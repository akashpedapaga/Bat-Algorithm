{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CvvFd3ndoiPt"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd   \n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import fbeta_score, cohen_kappa_score\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "QnlvZqK6o_Wg",
    "outputId": "fdfafffc-3dea-4418-c8ac-ca3316a4b71b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file using the correct relative file path\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\diabetes.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqUdEdpOo_1m",
    "outputId": "ea5f3168-0005-4283-87e6-0be09ba285e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (614, 8)\n",
      "y_train (614,)\n",
      "X_test (154, 8)\n",
      "y_test (154,)\n"
     ]
    }
   ],
   "source": [
    "# Split the DataFrame into features (X) and target variable (y)\n",
    "X = df.drop(\"Outcome\", axis=1)  # axis=0 for row, axis=1 for column\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "# Split the data into training and testing sets using an 80:20 ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# Print the shapes of the training and testing sets to verify the split\n",
    "print(\"X_train\", X_train.shape)  # Shape of the training features\n",
    "print(\"y_train\", y_train.shape)  # Shape of the training target variable\n",
    "print(\"X_test\", X_test.shape)  # Shape of the testing features\n",
    "print(\"y_test\", y_test.shape)  # Shape of the testing target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ASeMMg8oo_4B",
    "outputId": "d7416000-4b69-43ee-eb63-7cf0e5d4fe01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn_nature_inspired_algorithms==0.4.3\n",
      "  Using cached sklearn_nature_inspired_algorithms-0.4.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting NiaPy==2.0.0rc10 (from sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Using cached NiaPy-2.0.0rc10-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.2.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from sklearn_nature_inspired_algorithms==0.4.3) (3.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.18.4 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from sklearn_nature_inspired_algorithms==0.4.3) (1.26.4)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.0.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from sklearn_nature_inspired_algorithms==0.4.3) (1.5.3)\n",
      "Collecting scikit-learn<0.23.0,>=0.22.2 (from sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Using cached scikit-learn-0.22.2.post1.tar.gz (6.9 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting seaborn<0.11.0,>=0.10.1 (from sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Using cached seaborn-0.10.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting toml<0.10,>=0.9 (from sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Using cached toml-0.9.6-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from NiaPy==2.0.0rc10->sklearn_nature_inspired_algorithms==0.4.3) (1.10.1)\n",
      "Collecting enum34>=1.1.6 (from NiaPy==2.0.0rc10->sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Using cached enum34-1.1.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xlsxwriter>=1.1.5 (from NiaPy==2.0.0rc10->sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Using cached XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (23.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pandas<2.0.0,>=1.0.3->sklearn_nature_inspired_algorithms==0.4.3) (2022.7)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from scikit-learn<0.23.0,>=0.22.2->sklearn_nature_inspired_algorithms==0.4.3) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (1.16.0)\n",
      "Using cached sklearn_nature_inspired_algorithms-0.4.3-py3-none-any.whl (9.6 kB)\n",
      "Using cached NiaPy-2.0.0rc10-py3-none-any.whl (212 kB)\n",
      "Using cached seaborn-0.10.1-py3-none-any.whl (215 kB)\n",
      "Using cached toml-0.9.6-py2.py3-none-any.whl (14 kB)\n",
      "Using cached enum34-1.1.10-py3-none-any.whl (11 kB)\n",
      "Using cached XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "Building wheels for collected packages: scikit-learn\n",
      "  Building wheel for scikit-learn (setup.py): started\n",
      "  Building wheel for scikit-learn (setup.py): still running...\n",
      "  Building wheel for scikit-learn (setup.py): still running...\n",
      "  Building wheel for scikit-learn (setup.py): still running...\n",
      "  Building wheel for scikit-learn (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for scikit-learn\n",
      "Failed to build scikit-learn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1477 lines of output]\n",
      "      C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-x9njpkoy\\scikit-learn_70b9d4891bcd4e28833c1a3c66f03d50\\setup.py:12: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "        from pkg_resources import parse_version\n",
      "      Partial import of sklearn during the build process.\n",
      "      C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-x9njpkoy\\scikit-learn_70b9d4891bcd4e28833c1a3c66f03d50\\setup.py:123: DeprecationWarning:\n",
      "      \n",
      "        `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "        of the deprecation of `distutils` itself. It will be removed for\n",
      "        Python >= 3.12. For older Python versions it will remain present.\n",
      "        It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "        For more details, see:\n",
      "          https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "      \n",
      "      \n",
      "        from numpy.distutils.command.build_ext import build_ext  # noqa\n",
      "      INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "      INFO: C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um /Tctest_program.c /Foobjects\\test_program.obj\n",
      "      INFO: C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22621.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22621.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe\n",
      "      INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "      INFO: C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um /Tctest_program.c /Foobjects\\test_program.obj /openmp\n",
      "      INFO: C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22621.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22621.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe /openmp\n",
      "      Compiling sklearn\\__check_build\\_check_build.pyx because it changed.\n",
      "      Compiling sklearn\\preprocessing\\_csr_polynomial_expansion.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_dbscan_inner.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_hierarchical_fast.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_k_means_elkan.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_k_means_fast.pyx because it changed.\n",
      "      Compiling sklearn\\datasets\\_svmlight_format_fast.pyx because it changed.\n",
      "      Compiling sklearn\\decomposition\\_online_lda_fast.pyx because it changed.\n",
      "      Compiling sklearn\\decomposition\\_cdnmf_fast.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_gradient_boosting.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx because it changed.\n",
      "      Compiling sklearn\\feature_extraction\\_hashing_fast.pyx because it changed.\n",
      "      Compiling sklearn\\manifold\\_utils.pyx because it changed.\n",
      "      Compiling sklearn\\manifold\\_barnes_hut_tsne.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_pairwise_fast.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_ball_tree.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_kd_tree.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_dist_metrics.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_typedefs.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_quad_tree.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_tree.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_splitter.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_criterion.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_utils.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\sparsefuncs_fast.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_cython_blas.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\arrayfuncs.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\murmurhash.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\graph_shortest_path.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_fast_dict.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_openmp_helpers.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_seq_dataset.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_weight_vector.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_random.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_logistic_sigmoid.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_libsvm.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_liblinear.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_libsvm_sparse.pyx because it changed.\n",
      "      Compiling sklearn\\linear_model\\_cd_fast.pyx because it changed.\n",
      "      Compiling sklearn\\linear_model\\_sgd_fast.pyx because it changed.\n",
      "      Compiling sklearn\\linear_model\\_sag_fast.pyx because it changed.\n",
      "      Compiling sklearn\\_isotonic.pyx because it changed.\n",
      "      Partial import of sklearn during the build process.\n",
      "      Partial import of sklearn during the build process.\n",
      "      Partial import of sklearn during the build process.\n",
      "      Partial import of sklearn during the build process.\n",
      "      [ 1/50] Cythonizing sklearn\\__check_build\\_check_build.pyx\n",
      "      [ 2/50] Cythonizing sklearn\\_isotonic.pyx\n",
      "      [ 3/50] Cythonizing sklearn\\cluster\\_dbscan_inner.pyx\n",
      "      [ 4/50] Cythonizing sklearn\\cluster\\_hierarchical_fast.pyx\n",
      "      [ 5/50] Cythonizing sklearn\\cluster\\_k_means_elkan.pyx\n",
      "      warning: sklearn\\cluster\\_dbscan_inner.pyx:15:5: Only extern functions can throw C++ exceptions.\n",
      "      [ 6/50] Cythonizing sklearn\\cluster\\_k_means_fast.pyx\n",
      "      performance hint: sklearn\\cluster\\_k_means_elkan.pyx:20:5: Exception check on 'euclidean_dist' will always require the GIL to be acquired. Declare 'euclidean_dist' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [ 7/50] Cythonizing sklearn\\datasets\\_svmlight_format_fast.pyx\n",
      "      [ 8/50] Cythonizing sklearn\\decomposition\\_cdnmf_fast.pyx\n",
      "      [ 9/50] Cythonizing sklearn\\decomposition\\_online_lda_fast.pyx\n",
      "      [10/50] Cythonizing sklearn\\ensemble\\_gradient_boosting.pyx\n",
      "      [11/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [12/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [13/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx\n",
      "      [14/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx:92:5: Exception check on '_compute_softmax' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_compute_softmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_softmax' to allow an error code to be returned.\n",
      "      [15/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx\n",
      "      [16/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx\n",
      "      [17/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "      warning: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:18:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "      warning: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:259:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx:84:24: Exception check after calling '_compute_softmax' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_compute_softmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_softmax' to allow an error code to be returned.\n",
      "      [18/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:243:6: Exception check on '_build_histogram_naive' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_naive' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_naive' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:267:6: Exception check on '_subtract_histograms' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:291:6: Exception check on '_build_histogram' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:338:6: Exception check on '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:382:6: Exception check on '_build_histogram_root' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:435:6: Exception check on '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "      [19/50] Cythonizing sklearn\\feature_extraction\\_hashing_fast.pyx\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:155:60: Exception check after calling '_compute_histogram_brute_single_feature' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_compute_histogram_brute_single_feature' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_histogram_brute_single_feature' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:181:48: Exception check after calling '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:185:37: Exception check after calling '_build_histogram_root' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:190:43: Exception check after calling '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:194:32: Exception check after calling '_build_histogram' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:235:32: Exception check after calling '_subtract_histograms' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:404:58: Exception check after calling '_find_best_bin_to_split_left_to_right' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_find_best_bin_to_split_left_to_right' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_find_best_bin_to_split_left_to_right' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:413:62: Exception check after calling '_find_best_bin_to_split_right_to_left' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_find_best_bin_to_split_right_to_left' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_find_best_bin_to_split_right_to_left' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:418:70: Exception check after calling '_find_best_feature_to_split_helper' will always require the GIL to be acquired. Declare '_find_best_feature_to_split_helper' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [20/50] Cythonizing sklearn\\linear_model\\_cd_fast.pyx\n",
      "      [21/50] Cythonizing sklearn\\linear_model\\_sag_fast.pyx\n",
      "      [22/50] Cythonizing sklearn\\linear_model\\_sgd_fast.pyx\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1201:5: Exception check on 'predict_sample64' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1248:5: Exception check on 'predict_sample32' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:821:5: Exception check on 'l1penalty' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:466:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:494:32: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:499:36: Exception check after calling '_dloss' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_dloss' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:502:45: Exception check after calling '_dloss' will always require the GIL to be acquired. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [23/50] Cythonizing sklearn\\manifold\\_barnes_hut_tsne.pyx\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:797:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:825:32: Exception check after calling 'predict_sample32' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:830:36: Exception check after calling '_dloss' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_dloss' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:833:45: Exception check after calling '_dloss' will always require the GIL to be acquired. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1336:24: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1340:28: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1344:28: Exception check after calling '_dloss' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_dloss' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1347:39: Exception check after calling '_loss' will always require the GIL to be acquired. Declare '_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [24/50] Cythonizing sklearn\\manifold\\_utils.pyx\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [25/50] Cythonizing sklearn\\metrics\\_pairwise_fast.pyx\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:48:5: Exception check on 'fmax' will always require the GIL to be acquired. Declare 'fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:54:5: Exception check on 'fsign' will always require the GIL to be acquired. Declare 'fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:63:5: Exception check on 'abs_max' will always require the GIL to be acquired. Declare 'abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:75:5: Exception check on 'max' will always require the GIL to be acquired. Declare 'max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:87:5: Exception check on 'diff_abs_max' will always require the GIL to be acquired. Declare 'diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:669:31: Exception check after calling 'shuffle' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'shuffle' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'shuffle' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:671:28: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:679:25: Exception check after calling 'dot' will always require the GIL to be acquired. Declare 'dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:686:40: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:697:45: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:700:38: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:702:39: Exception check after calling '_dloss' will always require the GIL to be acquired. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:724:27: Exception check after calling 'scale' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'scale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'scale' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:726:25: Exception check after calling 'add' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'add' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:735:33: Exception check after calling 'add_average' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'add_average' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add_average' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:742:29: Exception check after calling 'l1penalty' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "      [26/50] Cythonizing sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx\n",
      "      performance hint: sklearn\\manifold\\_barnes_hut_tsne.pyx:222:30: Exception check after calling 'summarize' will always require the GIL to be acquired. Declare 'summarize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [27/50] Cythonizing sklearn\\neighbors\\_ball_tree.pyx\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:613:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:621:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:683:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1196:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1205:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1782:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [28/50] Cythonizing sklearn\\neighbors\\_dist_metrics.pyx\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:19:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:29:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:38:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:42:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:65:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:68:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:75:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:77:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_ball_tree.pyx:109:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_ball_tree.pyx:125:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_ball_tree.pyx:136:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:19:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:29:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:38:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:42:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:65:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:68:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:75:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:77:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [29/50] Cythonizing sklearn\\neighbors\\_kd_tree.pyx\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:613:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:621:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:683:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:294:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:302:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:334:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:338:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:415:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:419:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:422:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:425:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:451:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:463:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:466:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:469:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:492:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:513:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:544:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:552:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:555:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:558:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:599:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:611:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:614:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:617:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1196:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1205:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1782:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_kd_tree.pyx:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_kd_tree.pyx:152:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\neighbors\\_binary_tree.pxi:557:5: Exception check on 'dual_swap' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dual_swap' to allow an error code to be returned.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:664:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:684:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:687:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:690:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:713:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:735:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:758:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:784:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:814:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:838:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:863:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:888:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:912:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:936:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:960:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:988:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:998:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:1007:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:1010:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:1107:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:156:13: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:157:13: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:161:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:179:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:182:26: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:187:34: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:187:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:192:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:30: Exception check after calling '__pyx_fuse_0fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_0fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:198:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:208:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:209:21: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:217:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:220:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:223:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:233:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:237:38: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:156:13: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:157:13: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:161:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:179:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:182:26: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:187:34: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:187:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:192:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:30: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:198:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:208:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:209:21: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:217:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:220:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:223:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:233:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:237:38: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:345:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:388:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:388:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:429:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:431:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:434:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:437:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:446:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:448:54: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:345:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:388:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:388:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:429:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:431:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:434:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:437:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:446:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:448:54: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:547:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:560:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:577:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:582:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:584:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:593:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:604:37: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:547:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:560:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:577:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:582:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:584:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:593:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:604:37: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:696:24: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:700:25: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:715:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:718:24: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:720:24: Exception check after calling '__pyx_fuse_0_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:725:21: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:729:26: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:732:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:733:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:733:21: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:737:24: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:740:24: Exception check after calling '__pyx_fuse_0_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:745:37: Exception check after calling '__pyx_fuse_0diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:750:38: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:762:42: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:771:41: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:779:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:780:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:799:37: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:696:24: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:700:25: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:715:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:718:24: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:720:24: Exception check after calling '__pyx_fuse_1_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:725:21: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:729:26: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:732:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:733:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:733:21: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:737:24: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:740:24: Exception check after calling '__pyx_fuse_1_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:745:37: Exception check after calling '__pyx_fuse_1diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:750:38: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:762:42: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:771:41: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:779:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:780:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:799:37: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "              # determine number of levels in the tree, and from this\n",
      "              # the number of nodes in the tree.  This results in leaf nodes\n",
      "              # with numbers of points between leaf_size and 2 * leaf_size\n",
      "              self.n_levels = np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1\n",
      "              self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                                  ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\neighbors\\_binary_tree.pxi:1095:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'int')\n",
      "      [30/50] Cythonizing sklearn\\neighbors\\_quad_tree.pyx\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:19:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:29:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:38:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:42:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:65:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:68:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:75:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:77:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:137:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:326:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:485:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:579:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:591:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\neighbors\\_binary_tree.pxi:557:5: Exception check on 'dual_swap' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dual_swap' to allow an error code to be returned.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "              # determine number of levels in the tree, and from this\n",
      "              # the number of nodes in the tree.  This results in leaf nodes\n",
      "              # with numbers of points between leaf_size and 2 * leaf_size\n",
      "              self.n_levels = np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1\n",
      "              self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                                  ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\neighbors\\_binary_tree.pxi:1095:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'int')\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_ball_tree.pyx\n",
      "      [31/50] Cythonizing sklearn\\neighbors\\_typedefs.pyx\n",
      "      [32/50] Cythonizing sklearn\\preprocessing\\_csr_polynomial_expansion.pyx\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          def __cinit__(self, int n_dimensions, int verbose):\n",
      "              \"\"\"Constructor.\"\"\"\n",
      "              # Parameters of the tree\n",
      "              self.n_dimensions = n_dimensions\n",
      "              self.verbose = verbose\n",
      "              self.n_cells_per_cell = 2 ** self.n_dimensions\n",
      "                                        ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\neighbors\\_quad_tree.pyx:77:34: Cannot assign type 'double' to 'SIZE_t' (alias of 'int')\n",
      "      [33/50] Cythonizing sklearn\\svm\\_liblinear.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              arr = PyArray_NewFromDescr(<PyTypeObject *> np.ndarray,\n",
      "                                         CELL_DTYPE, 1, shape,\n",
      "                                         strides, <void*> self.cells,\n",
      "                                         np.NPY_DEFAULT, None)\n",
      "              Py_INCREF(self)\n",
      "              arr.base = <PyObject*> self\n",
      "                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\neighbors\\_quad_tree.pyx:576:11: Assignment to a read-only property\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              free_problem(problem)\n",
      "              free_parameter(param)\n",
      "              raise ValueError(error_msg)\n",
      "      \n",
      "          cdef BlasFunctions blas_functions\n",
      "          blas_functions.dot = _dot[double]\n",
      "                                   ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\svm\\_liblinear.pyx:55:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              free_parameter(param)\n",
      "              raise ValueError(error_msg)\n",
      "      \n",
      "          cdef BlasFunctions blas_functions\n",
      "          blas_functions.dot = _dot[double]\n",
      "          blas_functions.axpy = _axpy[double]\n",
      "                                     ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\svm\\_liblinear.pyx:56:31: Cannot assign type 'void (int, double, double *, int, double *, int) except * nogil' to 'axpy_func' (alias of 'void (*)(int, double, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              raise ValueError(error_msg)\n",
      "      \n",
      "          cdef BlasFunctions blas_functions\n",
      "          blas_functions.dot = _dot[double]\n",
      "          blas_functions.axpy = _axpy[double]\n",
      "          blas_functions.scal = _scal[double]\n",
      "                                     ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\svm\\_liblinear.pyx:57:31: Cannot assign type 'void (int, double, double *, int) except * nogil' to 'scal_func' (alias of 'void (*)(int, double, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "          cdef BlasFunctions blas_functions\n",
      "          blas_functions.dot = _dot[double]\n",
      "          blas_functions.axpy = _axpy[double]\n",
      "          blas_functions.scal = _scal[double]\n",
      "          blas_functions.nrm2 = _nrm2[double]\n",
      "                                     ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\svm\\_liblinear.pyx:58:31: Cannot assign type 'double (int, double *, int) except * nogil' to 'nrm2_func' (alias of 'double (*)(int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\svm\\_liblinear.pyx\n",
      "      [34/50] Cythonizing sklearn\\svm\\_libsvm.pyx\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_kd_tree.pyx\n",
      "      [35/50] Cythonizing sklearn\\svm\\_libsvm_sparse.pyx\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_quad_tree.pyx\n",
      "      [36/50] Cythonizing sklearn\\tree\\_criterion.pyx\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [37/50] Cythonizing sklearn\\tree\\_splitter.pyx\n",
      "      [38/50] Cythonizing sklearn\\tree\\_tree.pyx\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [39/50] Cythonizing sklearn\\tree\\_utils.pyx\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:56:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:82:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:90:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:97:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:281:76: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:346:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:373:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:400:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:742:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:783:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:794:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:805:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:284:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:1026:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:1074:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:1106:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:1135:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:188:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:218:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:285:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:601:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:1119:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:1348:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:433:76: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:683:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:695:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:729:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:29:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:114:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:230:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:318:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:335:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:493:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:507:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:29:5: Exception check on 'safe_realloc' will always require the GIL to be acquired. Declare 'safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pxd:55:20: No exception value declared for 'rand_int' in pxd file.\n",
      "      Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "      Suggest adding an explicit exception value.\n",
      "      performance hint: sklearn\\tree\\_utils.pxd:59:24: No exception value declared for 'rand_uniform' in pxd file.\n",
      "      Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "      Suggest adding an explicit exception value.\n",
      "      performance hint: sklearn\\tree\\_utils.pxd:63:15: No exception value declared for 'log' in pxd file.\n",
      "      Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "      Suggest adding an explicit exception value.\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:46:5: Exception check on '_init_split' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_init_split' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_init_split' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:479:5: Exception check on 'sort' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sort' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:486:5: Exception check on 'swap' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'swap' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:515:5: Exception check on 'introsort' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'introsort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'introsort' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:548:5: Exception check on 'sift_down' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sift_down' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sift_down' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:571:5: Exception check on 'heapsort' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapsort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapsort' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:963:5: Exception check on 'binary_search' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'binary_search' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:988:5: Exception check on 'extract_nnz_index_to_samples' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'extract_nnz_index_to_samples' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_index_to_samples' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:1028:5: Exception check on 'extract_nnz_binary_search' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'extract_nnz_binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_binary_search' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:1100:5: Exception check on 'sparse_swap' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sparse_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sparse_swap' to allow an error code to be returned.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          if not is_samples_sorted[0]:\n",
      "              n_samples = end - start\n",
      "              memcpy(sorted_samples + start, samples + start,\n",
      "                     n_samples * sizeof(SIZE_t))\n",
      "              qsort(sorted_samples + start, n_samples, sizeof(SIZE_t),\n",
      "                    compare_SIZE_t)\n",
      "                    ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\tree\\_splitter.pyx:1056:14: Cannot assign type 'int (const void *, const void *) except? -1 nogil' to 'int (*)(const void *, const void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of 'compare_SIZE_t'.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:169:30: Exception check after calling 'children_impurity' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'children_impurity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'children_impurity' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:200:30: Exception check after calling 'children_impurity' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'children_impurity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'children_impurity' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:537:44: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:572:49: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:577:50: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1068:89: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1097:74: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1099:62: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1126:75: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1128:63: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1168:70: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1184:69: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1246:74: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1258:75: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\tree\\_splitter.pyx\n",
      "      [40/50] Cythonizing sklearn\\utils\\_cython_blas.pyx\n",
      "      [41/50] Cythonizing sklearn\\utils\\_fast_dict.pyx\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:127:24: Exception check after calling '__pyx_fuse_9safe_realloc' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_9safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:205:27: Exception check after calling 'heapify_up' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapify_up' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_up' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:225:29: Exception check after calling 'heapify_down' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapify_down' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_down' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:243:24: Exception check after calling '__pyx_fuse_10safe_realloc' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_10safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:259:23: Exception check after calling 'heapify_up' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapify_up' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_up' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:281:29: Exception check after calling 'heapify_down' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapify_down' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_down' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:326:20: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:349:24: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:491:32: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:516:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:517:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:520:47: Exception check after calling 'update_median_parameters_post_push' will always require the GIL to be acquired. Declare 'update_median_parameters_post_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:531:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:551:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:554:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:560:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:563:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:573:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:574:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:576:42: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:577:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:588:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:589:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:592:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:595:39: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:596:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:607:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:614:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:635:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:638:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:645:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:648:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:656:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:657:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:660:52: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:20:5: Exception check on '_dot' will always require the GIL to be acquired. Declare '_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [42/50] Cythonizing sklearn\\utils\\_logistic_sigmoid.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "              # Initial capacity\n",
      "              cdef int init_capacity\n",
      "      \n",
      "              if tree.max_depth <= 10:\n",
      "                  init_capacity = (2 ** (tree.max_depth + 1)) - 1\n",
      "                                                              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\tree\\_tree.pyx:162:56: Cannot assign type 'double' to 'int'\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              shape[1] = <np.npy_intp> self.n_outputs\n",
      "              shape[2] = <np.npy_intp> self.max_n_classes\n",
      "              cdef np.ndarray arr\n",
      "              arr = np.PyArray_SimpleNewFromData(3, shape, np.NPY_DOUBLE, self.value)\n",
      "              Py_INCREF(self)\n",
      "              arr.base = <PyObject*> self\n",
      "                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\tree\\_tree.pyx:1103:11: Assignment to a read-only property\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              arr = PyArray_NewFromDescr(<PyTypeObject *> np.ndarray,\n",
      "                                         <np.dtype> NODE_DTYPE, 1, shape,\n",
      "                                         strides, <void*> self.nodes,\n",
      "                                         np.NPY_DEFAULT, None)\n",
      "              Py_INCREF(self)\n",
      "              arr.base = <PyObject*> self\n",
      "                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\tree\\_tree.pyx:1124:11: Assignment to a read-only property\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:33:5: Exception check on '_asum' will always require the GIL to be acquired. Declare '_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:45:5: Exception check on '_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:58:5: Exception check on '_nrm2' will always require the GIL to be acquired. Declare '_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:70:5: Exception check on '_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:82:5: Exception check on '_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_scal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:94:5: Exception check on '_rotg' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_rotg' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rotg' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:107:5: Exception check on '_rot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_rot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rot' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:124:5: Exception check on '_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:153:5: Exception check on '_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:183:5: Exception check on '_gemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemm' to allow an error code to be returned.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              dec(end)\n",
      "              # Construct our arguments\n",
      "              cdef pair[ITYPE_t, DTYPE_t] args\n",
      "              args.first = key\n",
      "              args.second = value\n",
      "              self.my_map.insert(end, args)\n",
      "                                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_fast_dict.pyx:138:27: Cannot assign type 'iterator' to 'const_iterator'\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\tree\\_tree.pyx\n",
      "      [43/50] Cythonizing sklearn\\utils\\_openmp_helpers.pyx\n",
      "      warning: sklearn\\utils\\_openmp_helpers.pyx:1:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "      warning: sklearn\\utils\\_openmp_helpers.pyx:44:4: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "      [44/50] Cythonizing sklearn\\utils\\_random.pyx\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\utils\\_fast_dict.pyx\n",
      "      [45/50] Cythonizing sklearn\\utils\\_seq_dataset.pyx\n",
      "      [46/50] Cythonizing sklearn\\utils\\_weight_vector.pyx\n",
      "      [47/50] Cythonizing sklearn\\utils\\arrayfuncs.pyx\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:80:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:81:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:117:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:118:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:24:19: Exception check after calling 'sdot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sdot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:26:19: Exception check after calling 'ddot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'ddot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:405:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:36:20: Exception check after calling 'sasum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sasum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:38:20: Exception check after calling 'dasum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dasum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:49:13: Exception check after calling 'saxpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'saxpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'saxpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:51:13: Exception check after calling 'daxpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'daxpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'daxpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:61:20: Exception check after calling 'snrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'snrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:406:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:442:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:443:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:63:20: Exception check after calling 'dnrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dnrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:73:13: Exception check after calling 'scopy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'scopy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'scopy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:75:13: Exception check after calling 'dcopy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dcopy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dcopy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:85:13: Exception check after calling 'sscal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sscal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sscal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:87:13: Exception check after calling 'dscal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dscal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dscal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:97:13: Exception check after calling 'srotg' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'srotg' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'srotg' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:99:13: Exception check after calling 'drotg' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'drotg' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'drotg' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:111:12: Exception check after calling 'srot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'srot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'srot' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:113:12: Exception check after calling 'drot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'drot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'drot' to allow an error code to be returned.\n",
      "      [48/50] Cythonizing sklearn\\utils\\graph_shortest_path.pyx\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:132:17: Exception check after calling 'sgemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sgemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sgemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:137:17: Exception check after calling 'sgemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sgemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sgemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:134:17: Exception check after calling 'dgemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dgemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dgemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:139:17: Exception check after calling 'dgemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dgemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dgemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:158:16: Exception check after calling 'sger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:163:16: Exception check after calling 'sger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:160:16: Exception check after calling 'dger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:165:16: Exception check after calling 'dger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:192:17: Exception check after calling 'sgemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sgemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sgemm' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:199:17: Exception check after calling 'sgemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sgemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sgemm' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:195:17: Exception check after calling 'dgemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dgemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dgemm' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:202:17: Exception check after calling 'dgemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dgemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dgemm' to allow an error code to be returned.\n",
      "      [49/50] Cythonizing sklearn\\utils\\murmurhash.pyx\n",
      "      [50/50] Cythonizing sklearn\\utils\\sparsefuncs_fast.pyx\n",
      "      performance hint: sklearn\\utils\\_weight_vector.pyx:169:29: Exception check after calling 'reset_wscale' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'reset_wscale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'reset_wscale' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_weight_vector.pyx:174:17: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_weight_vector.pyx:176:17: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_weight_vector.pyx:180:13: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "      multiprocessing.pool.RemoteTraceback:\n",
      "      \"\"\"\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "          result = (True, func(*args, **kwds))\n",
      "                          ^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 48, in mapstar\n",
      "          return list(map(*args))\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_ball_tree.pyx\n",
      "      \"\"\"\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-x9njpkoy\\scikit-learn_70b9d4891bcd4e28833c1a3c66f03d50\\setup.py\", line 303, in <module>\n",
      "          setup_package()\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-x9njpkoy\\scikit-learn_70b9d4891bcd4e28833c1a3c66f03d50\\setup.py\", line 299, in setup_package\n",
      "          setup(**metadata)\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 136, in setup\n",
      "          config = configuration()\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-x9njpkoy\\scikit-learn_70b9d4891bcd4e28833c1a3c66f03d50\\setup.py\", line 182, in configuration\n",
      "          config.add_subpackage('sklearn')\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1050, in add_subpackage\n",
      "          config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1016, in get_subpackage\n",
      "          config = self._get_configuration_from_setup_py(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 958, in _get_configuration_from_setup_py\n",
      "          config = setup_module.configuration(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-x9njpkoy\\scikit-learn_70b9d4891bcd4e28833c1a3c66f03d50\\sklearn\\setup.py\", line 86, in configuration\n",
      "          cythonize_extensions(top_path, config)\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-x9njpkoy\\scikit-learn_70b9d4891bcd4e28833c1a3c66f03d50\\sklearn\\_build_utils\\__init__.py\", line 75, in cythonize_extensions\n",
      "          config.ext_modules = cythonize(\n",
      "                               ^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1145, in cythonize\n",
      "          result.get(99999)  # seconds\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 774, in get\n",
      "          raise self._value\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_ball_tree.pyx\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-learn\n",
      "ERROR: Could not build wheels for scikit-learn, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: NiaPy in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from NiaPy) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.2.4 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from NiaPy) (3.8.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from NiaPy) (1.5.3)\n",
      "Requirement already satisfied: openpyxl>=3.0.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from NiaPy) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->NiaPy) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->NiaPy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->NiaPy) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->NiaPy) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->NiaPy) (23.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->NiaPy) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->NiaPy) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->NiaPy) (2.8.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from openpyxl>=3.0.3->NiaPy) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->NiaPy) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2.4->NiaPy) (1.16.0)\n",
      "Requirement already satisfied: algorithms in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (0.1.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn_nature_inspired_algorithms==0.4.3\n",
    "! pip install NiaPy\n",
    "! pip install algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "I9lhabzRqzwq"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test, modelname):\n",
    "    # Make predictions using the model\n",
    "    y_pred1 = model.predict(X_test)\n",
    "\n",
    "    # Calculate various performance metrics\n",
    "    precision = precision_score(y_test, y_pred1)\n",
    "    recall = recall_score(y_test, y_pred1)\n",
    "    f1score = f1_score(y_test, y_pred1)\n",
    "    rocauc = roc_auc_score(y_test, y_pred1)\n",
    "    logloss = log_loss(y_test, y_pred1)\n",
    "    accuracy = accuracy_score(y_test, y_pred1)\n",
    "\n",
    "    # Create a DataFrame to store the evaluation metrics\n",
    "    df_model = pd.DataFrame(\n",
    "        {\n",
    "            \"model\": [modelname],\n",
    "            \"accuracy\": [accuracy],\n",
    "            \"precision\": [precision],\n",
    "            \"recall\": [recall],\n",
    "            \"f1score\": [f1score],\n",
    "            \"rocauc\": [rocauc],\n",
    "            \"logloss\": [logloss],\n",
    "            \"timetaken\": [time1],\n",
    "        }\n",
    "    )\n",
    "    return df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8yl1vg8DN6R",
    "outputId": "4418e80e-7153-49c7-f9ed-67d4cb49414b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(200, 2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "param_grid_rt = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"bootstrap\": bootstrap,\n",
    "}\n",
    "print(param_grid_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxbaIOToqEw5"
   },
   "source": [
    "NATURE INSPIRIED SEARCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 3 candidates, which might total in 9 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 1/5 finished\n",
      "Run 2/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 2/5 finished\n",
      "Run 3/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 3/5 finished\n",
      "Run 4/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 4/5 finished\n",
      "Run 5/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 5/5 finished\n",
      "Optimization finished, 3 candidates were fitted (totalling 9 fits)\n",
      "Time taken: 27.92031693458557 seconds\n",
      "           model  accuracy  precision    recall  f1score    rocauc   logloss  \\\n",
      "0  Random Forest  0.753247   0.673913  0.574074     0.62  0.712037  8.893888   \n",
      "\n",
      "      timetaken  \n",
      "0  1.713862e+09  \n"
     ]
    }
   ],
   "source": [
    "from sklearn_nature_inspired_algorithms.model_selection import (\n",
    "    NatureInspiredSearchCV,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "# Define the parameter grid for NatureInspiredSearchCV\n",
    "param_grid_rt = {\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]  # Valid options for max_features\n",
    "}\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "clf_1 = RandomForestClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV\n",
    "nia_search = NatureInspiredSearchCV(\n",
    "    clf_1,\n",
    "    param_grid_rt,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm=\"ba\",  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    error_score=\"raise\",  # Raise an error if fitting fails\n",
    ")\n",
    "\n",
    "# Fit NatureInspiredSearchCV\n",
    "nia_search.fit(X_train, y_train)\n",
    "\n",
    "# End the timer and print elapsed time\n",
    "print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "\n",
    "# Get the best estimator found during the search\n",
    "best_estimator = nia_search.best_estimator_\n",
    "\n",
    "# Evaluate the best estimator\n",
    "model1 = evaluate(best_estimator, X_test, y_test, \"Random Forest\")\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vG5IJX6fo_87",
    "outputId": "061ccd9d-0041-41ce-a25c-c85285c7e8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'log2'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5l36OJauk_z",
    "outputId": "21ea6073-ae47-40d7-9edf-90227481dc1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et = ExtraTreesClassifier()\n",
    "print(et.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xN83KMC-urht",
    "outputId": "57f2fe25-72db-4083-9ebf-50ea284df428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "param_grid_et = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"bootstrap\": bootstrap,\n",
    "}\n",
    "print(param_grid_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 3 candidates, which might total in 9 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 1/5 finished\n",
      "Run 2/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 2/5 finished\n",
      "Run 3/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 3/5 finished\n",
      "Run 4/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 4/5 finished\n",
      "Run 5/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 5/5 finished\n",
      "Optimization finished, 3 candidates were fitted (totalling 9 fits)\n",
      "Time taken: 3.1142404079437256 seconds\n",
      "        model  accuracy  precision    recall   f1score    rocauc    logloss  \\\n",
      "0  Extra Tree  0.720779   0.607843  0.574074  0.590476  0.687037  10.064137   \n",
      "\n",
      "   timetaken  \n",
      "0    3.11424  \n"
     ]
    }
   ],
   "source": [
    "from sklearn_nature_inspired_algorithms.model_selection import (\n",
    "    NatureInspiredSearchCV,\n",
    ")\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import time\n",
    "\n",
    "# Define the parameter grid for ExtraTreesClassifier\n",
    "param_grid_et = {\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"]  # Valid options for max_features\n",
    "}\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Initialize the ExtraTreesClassifier\n",
    "clf_2 = ExtraTreesClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV for ExtraTreesClassifier\n",
    "nia_search2 = NatureInspiredSearchCV(\n",
    "    clf_2,\n",
    "    param_grid_et,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm=\"ba\",  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    error_score=\"raise\",  # Raise an error if fitting fails\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit NatureInspiredSearchCV for ExtraTreesClassifier\n",
    "    nia_search2.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best estimator found during the search for ExtraTreesClassifier\n",
    "    ba_et = nia_search2.best_estimator_\n",
    "\n",
    "    # Evaluate the best estimator\n",
    "    model3 = evaluate(ba_et, X_test, y_test, \"Extra Tree\")\n",
    "\n",
    "    # Print the time taken for the fitting process\n",
    "    print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "\n",
    "    # Update the time taken in the model evaluation\n",
    "    model3.timetaken[0] = time.time() - time1\n",
    "\n",
    "    # Print the evaluation results\n",
    "    print(model3)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(\"Fitting failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lXMlBR4urnd",
    "outputId": "e8c0aeef-4dbb-4632-9538-e93537ace647"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting at most 2 candidates\n",
      "Optimization finished, 2 candidates were fitted\n",
      "Time taken: 62.23056721687317 seconds\n",
      "        model  accuracy  precision    recall   f1score    rocauc   logloss  \\\n",
      "0  Extra Tree   0.74026       0.64  0.592593  0.615385  0.706296  9.361988   \n",
      "\n",
      "   timetaken  \n",
      "0  62.230567  \n",
      "CPU times: total: 26.3 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "import time\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Define the parameter grid with valid options for 'max_features'\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [110],\n",
    "    'max_features': ['sqrt', 'log2'],  # Valid options for 'max_features'\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [5],\n",
    "    'n_estimators': [800]\n",
    "}\n",
    "\n",
    "# Initialize the ExtraTreesClassifier\n",
    "clf_2 = ExtraTreesClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV for ExtraTreesClassifier\n",
    "nia_search2 = NatureInspiredSearchCV(\n",
    "    clf_2,\n",
    "    param_grid,\n",
    "    algorithm='ba',  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit NatureInspiredSearchCV for ExtraTreesClassifier\n",
    "    nia_search2.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator found during the search for ExtraTreesClassifier\n",
    "    ba_et = nia_search2.best_estimator_\n",
    "    \n",
    "    # Evaluate the best estimator\n",
    "    model3 = evaluate(ba_et, X_test, y_test, 'Extra Tree')\n",
    "    \n",
    "    # Print the time taken for the fitting process\n",
    "    print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "    \n",
    "    # Update the time taken in the model evaluation\n",
    "    model3.timetaken[0] = time.time() - time1\n",
    "    \n",
    "    # Print the evaluation results\n",
    "    print(model3)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(\"Fitting failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThL-VQlNlnBW",
    "outputId": "d1cb66ca-b743-498f-a7db-154d3a7fa94d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 110,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 800}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hc6wOJdxgxH5",
    "outputId": "ff6ca357-fed1-4aad-e5eb-16b1c4d2794b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "print(dtc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLAohyaxgxLR",
    "outputId": "d091d9d9-44ad-497d-871c-953e054d1525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': ['auto', 'sqrt'], 'max_depth': [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210], 'min_samples_split': [2, 5, 10, 15], 'min_samples_leaf': [2, 4, 10]}\n"
     ]
    }
   ],
   "source": [
    "class_weight = [int(x) for x in np.linspace(start=10, stop=100, num=10)]\n",
    "class_weight.append(None)\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 210, num=11)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "# Create the random grid\n",
    "param_grid_dt = {  #'class_weight': class_weight,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "}\n",
    "print(param_grid_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9QPp2hRiETw",
    "outputId": "ab90288c-3f2f-4582-e7e0-f87eb89526e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 3 candidates, which might total in 9 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 1/5 finished\n",
      "Run 2/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 2/5 finished\n",
      "Run 3/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 3/5 finished\n",
      "Run 4/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 4/5 finished\n",
      "Run 5/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 5/5 finished\n",
      "Optimization finished, 3 candidates were fitted (totalling 9 fits)\n",
      "Time taken: 0.3953592777252197 seconds\n",
      "           model  accuracy  precision    recall   f1score    rocauc  \\\n",
      "0  Decision Tree  0.688312   0.555556  0.555556  0.555556  0.657778   \n",
      "\n",
      "     logloss  timetaken  \n",
      "0  11.234385   0.395359  \n",
      "CPU times: total: 156 ms\n",
      "Wall time: 403 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "import time\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Define the parameter grid with valid options for 'max_features'\n",
    "param_grid_dt = {\n",
    "    'max_features': ['sqrt', 'log2', None]  # Valid options for 'max_features'\n",
    "}\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "clf_3 = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV for DecisionTreeClassifier\n",
    "nia_search3 = NatureInspiredSearchCV(\n",
    "    clf_3,\n",
    "    param_grid_dt,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba',  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit NatureInspiredSearchCV for DecisionTreeClassifier\n",
    "    nia_search3.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator found during the search for DecisionTreeClassifier\n",
    "    ba_dt = nia_search3.best_estimator_\n",
    "    \n",
    "    # Evaluate the best estimator\n",
    "    model4 = evaluate(ba_dt, X_test, y_test, 'Decision Tree')\n",
    "    \n",
    "    # Print the time taken for the fitting process\n",
    "    print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "    \n",
    "    # Update the time taken in the model evaluation\n",
    "    model4.timetaken[0] = time.time() - time1\n",
    "    \n",
    "    # Print the evaluation results\n",
    "    print(model4)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(\"Fitting failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5Ig_jHKkcBt",
    "outputId": "a2c3fda6-b032-44b3-d3b8-89c91295ea0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'log2'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzVp4BHak6RF",
    "outputId": "2dd9fe46-3739-44b5-dac4-71e3ff8faa2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 1 candidates, which might total in 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 1/5 finished\n",
      "Run 2/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 2/5 finished\n",
      "Run 3/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 3/5 finished\n",
      "Run 4/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 4/5 finished\n",
      "Run 5/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 5/5 finished\n",
      "Optimization finished, 1 candidates were fitted (totalling 3 fits)\n",
      "Time taken: 0.9105446338653564 seconds\n",
      "           model  accuracy  precision    recall  f1score    rocauc   logloss  \\\n",
      "0  Decision Tree  0.727273   0.630435  0.537037     0.58  0.683519  9.830087   \n",
      "\n",
      "   timetaken  \n",
      "0   0.910545  \n",
      "CPU times: total: 406 ms\n",
      "Wall time: 911 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "import time\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Define the parameter grid with valid options for 'max_features'\n",
    "param_grid = {\n",
    "    'max_depth': [115],\n",
    "    'max_features': [None],  # Use None instead of 'auto'\n",
    "    'min_samples_leaf': [4],\n",
    "    'min_samples_split': [10],\n",
    "}\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "clf_3 = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV for DecisionTreeClassifier\n",
    "nia_search3 = NatureInspiredSearchCV(\n",
    "    clf_3,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba',  # Bat algorithm\n",
    "    population_size=150,\n",
    "    max_n_gen=200,\n",
    "    max_stagnating_gen=60,\n",
    "    runs=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit NatureInspiredSearchCV for DecisionTreeClassifier\n",
    "    nia_search3.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator found during the search for DecisionTreeClassifier\n",
    "    ba_dt = nia_search3.best_estimator_\n",
    "    \n",
    "    # Evaluate the best estimator\n",
    "    model3 = evaluate(ba_dt, X_test, y_test, 'Decision Tree')\n",
    "    \n",
    "    # Print the time taken for the fitting process\n",
    "    print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "    \n",
    "    # Update the time taken in the model evaluation\n",
    "    model3.timetaken[0] = time.time() - time1\n",
    "    \n",
    "    # Print the evaluation results\n",
    "    print(model3)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(\"Fitting failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9bGSBfikxWM",
    "outputId": "3bdf15bf-9dc2-4907-c4b7-03f91b2118d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 115,\n",
       " 'max_features': None,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBGWTINKo__K",
    "outputId": "4f4eb11d-cc64-4528-cb82-dc44f0e0a332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "print(lr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPIJy262pACh",
    "outputId": "027d8648-73f0-422e-e3c3-ee44350c03ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'C': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0]}\n"
     ]
    }
   ],
   "source": [
    "# Define a list of values for the 'max_iter' parameter\n",
    "max_iter = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "\n",
    "# Define a list of values for the 'C' parameter\n",
    "C = [float(x) for x in np.linspace(start=1, stop=20, num=20)]\n",
    "\n",
    "# Define a list of solvers to be tried\n",
    "solver = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "\n",
    "# Define a list of class weights to be tried\n",
    "class_weight = [int(x) for x in np.linspace(1, 10, num=10)]\n",
    "class_weight.append(None)\n",
    "\n",
    "# Define a list of values for the 'n_jobs' parameter\n",
    "n_jobs = [int(x) for x in np.linspace(1, 10, num=10)]\n",
    "\n",
    "# Define a list of values for the 'intercept_scaling' parameter\n",
    "intercept_scaling = [1, 2, 4]\n",
    "\n",
    "# Define a list of verbose levels to be tried\n",
    "verbose = [0, 1, 2, 3]\n",
    "\n",
    "# Define a list of values for the 'dual' parameter\n",
    "dual = [True, False]\n",
    "\n",
    "# Define a list of multi-class options to be tried\n",
    "multi_class = [\"auto\", \"ovr\", \"multinomial\"]\n",
    "\n",
    "# Define a list of values for the 'tol' parameter\n",
    "tol = [0.00001, 0.0001, 0.001, 0.01, 0.1, 0, 1]\n",
    "\n",
    "# Create the random grid by defining a dictionary of parameter grids\n",
    "param_grid_lr = {\n",
    "    \"max_iter\": max_iter,\n",
    "    \"solver\": solver,\n",
    "    \"C\": C,\n",
    "}\n",
    "\n",
    "# Print the random grid parameters\n",
    "print(param_grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJdP3H9Frt6k",
    "outputId": "319c4981-baa8-4ce7-8433-104838cd5658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 1000 candidates, which might total in 3000 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 38 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 53 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 64 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 74 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 83 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 92 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 98 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 102 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 112 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 119 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 128 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 136 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 140 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 148 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 158 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 170 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 180 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 184 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 192 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 195 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 201 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 224 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 232 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 239 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 246 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 249 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 254 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 260 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 265 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 270 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 273 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 277 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 279 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 287 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 290 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 295 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 299 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 300 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 304 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 306 candidates trained until now\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 306 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 310 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 330 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 333 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 334 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 338 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 339 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 341 candidates trained until now\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 341 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 343 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 347 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 348 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 350 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 352 candidates trained until now\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 352 candidates trained until now\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 352 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 355 candidates trained until now\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 355 candidates trained until now\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 355 candidates trained until now\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 355 candidates trained until now\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 355 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 360 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 362 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 362 candidates were fitted (totalling 1086 fits)\n",
      "Bat model\n",
      "Logistic Regression\n",
      "                 model  accuracy  precision    recall  f1score    rocauc  \\\n",
      "0  Logistic Regression  0.714286   0.608696  0.518519     0.56  0.669259   \n",
      "\n",
      "     logloss  timetaken  \n",
      "0  10.298187  56.259765  \n",
      "CPU times: total: 6.84 s\n",
      "Wall time: 56.3 s\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "time1 = time.time()\n",
    "\n",
    "# Instantiate a Logistic Regression classifier\n",
    "clf_1 = LogisticRegression()\n",
    "\n",
    "# Instantiate the NatureInspiredSearchCV object with the specified parameters\n",
    "nia_search1 = NatureInspiredSearchCV(\n",
    "    clf_1,\n",
    "    param_grid_lr,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba',  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the NatureInspiredSearchCV to the training data\n",
    "nia_search1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Bat model\")\n",
    "print(\"Logistic Regression\")\n",
    "\n",
    "# Get the best estimator found by the search\n",
    "ba_lr = nia_search1.best_estimator_\n",
    "\n",
    "# Evaluate the model using the evaluate function and record the time taken\n",
    "model2 = evaluate(ba_lr, X_test, y_test, 'Logistic Regression')\n",
    "model2.timetaken[0] = time.time() - time1\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95alnjqzrt_d",
    "outputId": "94d221ce-e0fd-4a61-882c-d14e1cff4a70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1800, 'solver': 'lbfgs', 'C': 6.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YH6lW7uJr2lD",
    "outputId": "5c3d7f9b-b4d8-44f6-f80c-f06c0ef28e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kn = KNeighborsClassifier()\n",
    "print(kn.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMmK02-wr5a8",
    "outputId": "5c5087e9-2663-47ee-b224-aa1f6c9d455b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': [100, 111, 122, 133, 144, 155, 166, 177, 188, 200], 'p': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n"
     ]
    }
   ],
   "source": [
    "# Define a list of leaf sizes ranging from 100 to 200 with 10 intervals\n",
    "leaf_size = [int(x) for x in np.linspace(start=100, stop=200, num=10)]\n",
    "\n",
    "# Define a list of algorithms to consider for nearest neighbors search\n",
    "algorithm = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "\n",
    "# Define a list of values for the parameter p, which represents the power parameter for the Minkowski metric\n",
    "p = [int(x) for x in np.linspace(1, 20, num=20)]\n",
    "\n",
    "# Create the parameter grid for the KNeighborsClassifier\n",
    "param_grid_kn = {\n",
    "    \"leaf_size\": leaf_size,  # Leaf size for the BallTree or KDTree\n",
    "    \"p\": p,  # Power parameter for the Minkowski metric\n",
    "    \"algorithm\": algorithm,  # Algorithm used to compute the nearest neighbors\n",
    "}\n",
    "\n",
    "# Print the parameter grid\n",
    "print(param_grid_kn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFNyXstJr5eg",
    "outputId": "8accbc61-b614-41db-9b8b-25a1409c8b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 800 candidates, which might total in 2400 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "An error occurred during fitting: 'NoneType' object has no attribute 'copy'\n",
      "CPU times: total: 250 ms\n",
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "time1 = time.time()\n",
    "\n",
    "# Instantiate a KNeighborsClassifier\n",
    "clf_4 = KNeighborsClassifier()\n",
    "\n",
    "# Create a NatureInspiredSearchCV object with specified parameters\n",
    "nia_search4 = NatureInspiredSearchCV(\n",
    "    clf_4,\n",
    "    param_grid_kn,  # Parameter grid for hyperparameter tuning\n",
    "    cv=3,  # Number of folds for cross-validation\n",
    "    verbose=2,  # Verbosity level\n",
    "    algorithm='ba',  # Algorithm to use for optimization (bat algorithm)\n",
    "    population_size=50,  # Size of the population of solutions\n",
    "    max_n_gen=100,  # Maximum number of generations\n",
    "    max_stagnating_gen=20,  # Maximum number of stagnating generations before termination\n",
    "    runs=3,  # Number of independent runs of the optimization algorithm\n",
    "    n_jobs=-1,  # Number of jobs to run in parallel (-1 for using all available cores)\n",
    "    random_state=42  # Random state for reproducibility\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit the NatureInspiredSearchCV object to the training data\n",
    "    nia_search4.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator from the search\n",
    "    ba_kn = nia_search4.best_estimator_\n",
    "    \n",
    "    # Evaluate the best model on the test data\n",
    "    model4 = evaluate(ba_kn, X_test, y_test, 'KNN')\n",
    "    \n",
    "    # Calculate the time taken for fitting and evaluation\n",
    "    model4.timetaken[0] = time.time() - time1\n",
    "    \n",
    "    # Print the evaluation metrics of the best model\n",
    "    print(model4)\n",
    "except AttributeError as e:\n",
    "    # Handle AttributeError exception if it occurs during fitting\n",
    "    print(\"An error occurred during fitting:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGw4cjQXufWc",
    "outputId": "1ee9629b-257e-4d6b-d348-527fffad4997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 6 candidates, which might total in 18 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 6 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 6 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 6 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 6 candidates were fitted (totalling 18 fits)\n",
      "Bat model\n",
      "KNN\n",
      "  model  accuracy  precision    recall   f1score    rocauc    logloss  \\\n",
      "0   KNN  0.668831   0.530612  0.481481  0.504854  0.625741  11.936535   \n",
      "\n",
      "   timetaken  \n",
      "0   0.760632  \n"
     ]
    }
   ],
   "source": [
    "from sklearn_nature_inspired_algorithms.model_selection import (\n",
    "    NatureInspiredSearchCV,\n",
    ")\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the reduced parameter grid\n",
    "param_grid = {\"leaf_size\": [30, 60, 90], \"p\": [1, 2]}\n",
    "\n",
    "# Start timing\n",
    "time1 = time.time()\n",
    "\n",
    "# Create the KNeighborsClassifier instance\n",
    "clf_4 = KNeighborsClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV\n",
    "nia_search4 = NatureInspiredSearchCV(\n",
    "    clf_4,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm=\"ba\",  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the search\n",
    "nia_search4.fit(X_train, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Bat model\")\n",
    "print(\"KNN\")\n",
    "\n",
    "# Retrieve the best estimator\n",
    "ba_kn = nia_search4.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "model4 = evaluate(ba_kn, X_test, y_test, \"KNN\")\n",
    "\n",
    "# Measure the time taken\n",
    "model4.timetaken[0] = time.time() - time1\n",
    "\n",
    "# Print the evaluation results\n",
    "print(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrj3uNwEvlE-",
    "outputId": "a5f7ba99-3318-4937-ebfa-74829db94c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': 'warn', 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC()\n",
    "print(lsvc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RMmKjyQvlHv",
    "outputId": "60709963-ef8c-4736-eecf-88da71c34e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': [1e-05, 0.001, 0.0001, 0.01, 0.1, 1], 'intercept_scaling': [1, 6, 11, 17, 22, 28, 33, 39, 44, 50], 'dual': [True, False], 'max_iter': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Define the class weights for balancing class frequencies\n",
    "class_weight = [int(x) for x in np.linspace(start=10, stop=110, num=11)]\n",
    "class_weight.append(None)  # Add None for default class weights\n",
    "\n",
    "# Define the intercept scaling values\n",
    "intercept_scaling = [int(x) for x in np.linspace(1, 50, num=10)]\n",
    "\n",
    "# Define the tolerance values for stopping criteria\n",
    "tol = [0.00001, 0.001, 0.0001, 0.01, 0.1, 1]\n",
    "\n",
    "# Define the choice between primal and dual optimization\n",
    "dual = [True, False]\n",
    "\n",
    "# Define the number of iterations for convergence\n",
    "itr = [int(x) for x in np.linspace(100, 2000, num=20)]\n",
    "\n",
    "# Create the random grid of hyperparameters for LinearSVC\n",
    "param_grid_lsvc = {\n",
    "    \"tol\": tol,  # Tolerance for stopping criteria\n",
    "    \"intercept_scaling\": intercept_scaling,  # Scaling factor of intercept\n",
    "    \"dual\": dual,  # Whether to use dual or primal formulation\n",
    "    \"max_iter\": itr,  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Print the parameter grid for LinearSVC\n",
    "print(param_grid_lsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3NCOZr5vlKl",
    "outputId": "9e4f73cb-9fad-4c07-d37b-d0e7ceae102a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 2400 candidates, which might total in 7200 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 34 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 48 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 58 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 66 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 72 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 79 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 88 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 92 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 101 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 108 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 119 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 126 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 134 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 142 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 155 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 172 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 179 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 190 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 200 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 209 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 219 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 254 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 265 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 277 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 283 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 292 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 297 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 306 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 308 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 309 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 313 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 315 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 325 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 331 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 339 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 344 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 349 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 353 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 359 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 368 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 374 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 376 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 400 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 407 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 411 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 416 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 417 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 418 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 420 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 422 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 425 candidates trained until now\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 425 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 426 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 429 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 431 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 439 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 450 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 459 candidates trained until now\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 459 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 460 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 461 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 472 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 474 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 474 candidates were fitted (totalling 1422 fits)\n",
      "Bat model\n",
      "LinearSVC\n",
      "       model  accuracy  precision    recall  f1score    rocauc    logloss  \\\n",
      "0  LinearSVC  0.714286   0.608696  0.518519     0.56  0.669259  10.298187   \n",
      "\n",
      "   timetaken  \n",
      "0  32.368061  \n",
      "CPU times: total: 10.6 s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn_nature_inspired_algorithms.model_selection import (\n",
    "    NatureInspiredSearchCV,\n",
    ")\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "time1 = time.time()\n",
    "\n",
    "# Instantiate the Linear Support Vector Classifier (LinearSVC) model\n",
    "clf_5 = LinearSVC()\n",
    "\n",
    "# Instantiate the NatureInspiredSearchCV object for hyperparameter tuning\n",
    "nia_search5 = NatureInspiredSearchCV(\n",
    "    clf_5,\n",
    "    param_grid_lsvc,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,  # Verbosity level set to 2\n",
    "    algorithm=\"ba\",  # Bat algorithm for optimization\n",
    "    population_size=50,  # Size of the population\n",
    "    max_n_gen=100,  # Maximum number of generations\n",
    "    max_stagnating_gen=20,  # Maximum number of stagnating generations\n",
    "    runs=3,  # Number of independent runs\n",
    "    n_jobs=-1,  # Utilize all available CPU cores\n",
    "    random_state=42,  # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Fit the NatureInspiredSearchCV object to the training data\n",
    "nia_search5.fit(X_train, y_train)\n",
    "\n",
    "# Print message indicating the completion of fitting\n",
    "print(\"Bat model\")\n",
    "\n",
    "# Print message indicating the model being trained\n",
    "print(\"LinearSVC\")\n",
    "\n",
    "# Get the best estimator from the hyperparameter tuning process\n",
    "ba_lsvc = nia_search5.best_estimator_\n",
    "\n",
    "# Evaluate the performance of the best estimator on the test data\n",
    "model5 = evaluate(ba_lsvc, X_test, y_test, \"LinearSVC\")\n",
    "\n",
    "# Calculate the time taken for fitting and evaluation\n",
    "model5.timetaken[0] = time.time() - time1\n",
    "\n",
    "# Print the evaluation results\n",
    "print(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGnKuZCIwU4O",
    "outputId": "36d9d2b4-31cf-4c3d-d70c-c916ab015cb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 1e-05, 'intercept_scaling': 50, 'dual': False, 'max_iter': 1600}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSKqvdW5w_YS",
    "outputId": "d8966e6d-cbfe-41c9-95fb-47e900cd5fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priors': None, 'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "print(gnb.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxCfVONkw_g-",
    "outputId": "305ccdac-8681-406a-a082-3f5d7ebbd7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': [1e-10, 1e-06, 0.01, 0.001, 1e-14, 1, 1e-15, 1e-20]}\n"
     ]
    }
   ],
   "source": [
    "# priors is a list containing training data X_train and corresponding labels y_train\n",
    "# It appends None to priors\n",
    "\n",
    "priors = [X_train, y_train]\n",
    "priors.append(None)\n",
    "\n",
    "# var_smoothing is a list containing various values used for smoothing in GaussianNB\n",
    "var_smoothing = [\n",
    "    0.0000000001,\n",
    "    0.000001,\n",
    "    0.01,\n",
    "    0.001,\n",
    "    0.00000000000001,\n",
    "    1,\n",
    "    1e-15,\n",
    "    1e-20,\n",
    "]\n",
    "\n",
    "# param_grid_gnb is a dictionary containing the parameters for tuning GaussianNB model\n",
    "param_grid_gnb = {\"var_smoothing\": var_smoothing}  # 'priors':priors,\n",
    "\n",
    "# Print the parameter grid for GaussianNB\n",
    "print(param_grid_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7bhXWMEw_kX",
    "outputId": "aab3041a-4e8f-4cd2-9c82-c2a250f2ba9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 8 candidates, which might total in 24 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 8 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 8 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 8 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 8 candidates were fitted (totalling 24 fits)\n",
      "Bat model\n",
      "GaussianNB\n",
      "        model  accuracy  precision    recall   f1score    rocauc    logloss  \\\n",
      "0  GaussianNB  0.701299   0.574074  0.574074  0.574074  0.672037  10.766286   \n",
      "\n",
      "   timetaken  \n",
      "0   0.526083  \n",
      "CPU times: total: 219 ms\n",
      "Wall time: 534 ms\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn_nature_inspired_algorithms.model_selection import (\n",
    "    NatureInspiredSearchCV,\n",
    ")\n",
    "import time\n",
    "\n",
    "# Record starting time\n",
    "time1 = time.time()\n",
    "\n",
    "# Instantiate GaussianNB classifier\n",
    "clf_6 = GaussianNB()\n",
    "\n",
    "# Create NatureInspiredSearchCV object with specified parameters\n",
    "nia_search6 = NatureInspiredSearchCV(\n",
    "    clf_6,\n",
    "    param_grid_gnb,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm=\"ba\",  # bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the NatureInspiredSearchCV object on training data\n",
    "nia_search6.fit(X_train, y_train)\n",
    "\n",
    "# Print information about the model\n",
    "print(\"Bat model\")\n",
    "print(\"GaussianNB\")\n",
    "\n",
    "# Get the best estimator from the search\n",
    "ba_gnb = nia_search6.best_estimator_\n",
    "\n",
    "# Evaluate the model using custom evaluate function\n",
    "model6 = evaluate(ba_gnb, X_test, y_test, \"GaussianNB\")\n",
    "\n",
    "# Calculate the time taken for fitting and evaluation\n",
    "model6.timetaken[0] = time.time() - time1\n",
    "\n",
    "# Print the evaluation results\n",
    "print(model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmgUiNSbyEL_",
    "outputId": "c1228168-fdce-4782-8baa-e2350ae14af9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB(var_smoothing=0.001)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB(var_smoothing=0.001)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nia_search6.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcmSGoOQycGt",
    "outputId": "bbaedd2e-18fd-4a3a-acd4-04a24b1acffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "print(svc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_46vJaaycI4",
    "outputId": "1d2a3a81-3061-4ab5-e755-f91a090804f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'tol': [1e-05, 0.001, 0.0001, 0.01, 0.1, 1], 'cache_size': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'break_ties': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "degree = [int(x) for x in np.linspace(start=1, stop=20, num=20)]\n",
    "# class_weight.append(None)\n",
    "cache_size = [int(x) for x in np.linspace(200, 2000, num=10)]\n",
    "# Minimum number of samples required to split a node\n",
    "tol = [0.00001, 0.001, 0.0001, 0.01, 0.1, 1]\n",
    "break_ties = [True, False]\n",
    "# Create the random grid\n",
    "param_grid_svc = {\n",
    "    \"degree\": degree,\n",
    "    \"tol\": tol,\n",
    "    \"cache_size\": cache_size,\n",
    "    \"break_ties\": break_ties,\n",
    "}\n",
    "print(param_grid_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kew0_5oZycMQ",
    "outputId": "4e888700-d976-43c6-e3a7-03d085671f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 2400 candidates, which might total in 7200 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 36 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 51 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 60 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 72 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 80 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 88 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 91 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 99 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 107 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 112 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 119 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 127 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 132 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 137 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 141 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 146 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 148 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 160 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 172 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 183 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 193 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 223 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 234 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 244 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 253 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 260 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 267 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 274 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 278 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 281 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 288 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 297 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 303 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 310 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 323 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 330 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 344 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 350 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 357 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 366 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 372 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 377 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 408 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 417 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 425 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 433 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 438 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 445 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 448 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 456 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 464 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 471 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 479 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 487 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 494 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 496 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 504 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 515 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 523 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 529 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 536 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 538 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 543 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 543 candidates were fitted (totalling 1629 fits)\n",
      "Bat model\n",
      "SVC\n",
      "  model  accuracy  precision    recall   f1score    rocauc    logloss  \\\n",
      "0   SVC  0.720779   0.648649  0.444444  0.527473  0.657222  10.064137   \n",
      "\n",
      "   timetaken  \n",
      "0  66.114929  \n",
      "CPU times: total: 13.9 s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn_nature_inspired_algorithms.model_selection import (\n",
    "    NatureInspiredSearchCV,\n",
    ")\n",
    "import time\n",
    "\n",
    "# Record starting time\n",
    "time1 = time.time()\n",
    "\n",
    "# Instantiate SVC classifier\n",
    "clf_8 = SVC()\n",
    "\n",
    "# Create NatureInspiredSearchCV object with specified parameters\n",
    "nia_search8 = NatureInspiredSearchCV(\n",
    "    clf_8,\n",
    "    param_grid_svc,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm=\"ba\",  # bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the NatureInspiredSearchCV object on training data\n",
    "nia_search8.fit(X_train, y_train)\n",
    "\n",
    "# Print information about the model\n",
    "print(\"Bat model\")\n",
    "print(\"SVC\")\n",
    "\n",
    "# Get the best estimator from the search\n",
    "ba_svc = nia_search8.best_estimator_\n",
    "\n",
    "# Evaluate the model using custom evaluate function\n",
    "model8 = evaluate(ba_svc, X_test, y_test, \"SVC\")\n",
    "\n",
    "# Calculate the time taken for fitting and evaluation\n",
    "model8.timetaken[0] = time.time() - time1\n",
    "\n",
    "# Print the evaluation results\n",
    "print(model8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzbnwmHHzA1V",
    "outputId": "21ea37db-d4d5-4a24-891e-d7992b392589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degree': 13, 'tol': 0.1, 'cache_size': 1000, 'break_ties': True}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search8.best_params_"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BatAlgorithm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
