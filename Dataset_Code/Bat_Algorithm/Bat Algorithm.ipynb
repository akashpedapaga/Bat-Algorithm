{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CvvFd3ndoiPt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import fbeta_score, cohen_kappa_score\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "QnlvZqK6o_Wg",
    "outputId": "fdfafffc-3dea-4418-c8ac-ca3316a4b71b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\Dataset\\\\diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdiabetes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\Dataset\\\\diabetes.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"..\\Dataset\\diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqUdEdpOo_1m",
    "outputId": "ea5f3168-0005-4283-87e6-0be09ba285e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (614, 8)\n",
      "y_train (614,)\n",
      "X_test (154, 8)\n",
      "y_test (154,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"Outcome\", axis=1)  # axis=0 for row, axis=1 for column\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "# split data to 80:20 ratio for train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ASeMMg8oo_4B",
    "outputId": "d7416000-4b69-43ee-eb63-7cf0e5d4fe01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn_nature_inspired_algorithms==0.4.3\n",
      "  Downloading sklearn_nature_inspired_algorithms-0.4.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting NiaPy==2.0.0rc10 (from sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Downloading NiaPy-2.0.0rc10-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.2.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from sklearn_nature_inspired_algorithms==0.4.3) (3.7.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.18.4 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from sklearn_nature_inspired_algorithms==0.4.3) (1.26.4)\n",
      "Collecting pandas<2.0.0,>=1.0.3 (from sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Downloading pandas-1.5.3-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting scikit-learn<0.23.0,>=0.22.2 (from sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Downloading scikit-learn-0.22.2.post1.tar.gz (6.9 MB)\n",
      "     ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/6.9 MB 4.5 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.6/6.9 MB 5.5 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 1.0/6.9 MB 6.3 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.1/6.9 MB 7.0 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.1/6.9 MB 4.5 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 2.1/6.9 MB 7.0 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.5/6.9 MB 7.1 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 2.7/6.9 MB 7.1 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 2.7/6.9 MB 7.1 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.2/6.9 MB 6.9 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.7/6.9 MB 7.2 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 4.1/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 4.4/6.9 MB 7.2 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 4.7/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 5.0/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 5.3/6.9 MB 7.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 5.6/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 5.9/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 6.2/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 6.6/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.9/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.9/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.9/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.9/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.9/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.9/6.9 MB 6.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting seaborn<0.11.0,>=0.10.1 (from sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Downloading seaborn-0.10.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting toml<0.10,>=0.9 (from sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Downloading toml-0.9.6-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from NiaPy==2.0.0rc10->sklearn_nature_inspired_algorithms==0.4.3) (1.10.1)\n",
      "Collecting enum34>=1.1.6 (from NiaPy==2.0.0rc10->sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Downloading enum34-1.1.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xlsxwriter>=1.1.5 (from NiaPy==2.0.0rc10->sklearn_nature_inspired_algorithms==0.4.3)\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pandas<2.0.0,>=1.0.3->sklearn_nature_inspired_algorithms==0.4.3) (2022.7)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from scikit-learn<0.23.0,>=0.22.2->sklearn_nature_inspired_algorithms==0.4.3) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.2.1->sklearn_nature_inspired_algorithms==0.4.3) (1.16.0)\n",
      "Downloading sklearn_nature_inspired_algorithms-0.4.3-py3-none-any.whl (9.6 kB)\n",
      "Downloading NiaPy-2.0.0rc10-py3-none-any.whl (212 kB)\n",
      "   ---------------------------------------- 0.0/212.4 kB ? eta -:--:--\n",
      "   ------------------------------------- - 204.8/212.4 kB 13.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 204.8/212.4 kB 13.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 204.8/212.4 kB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 212.4/212.4 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading pandas-1.5.3-cp311-cp311-win_amd64.whl (10.3 MB)\n",
      "   ---------------------------------------- 0.0/10.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/10.3 MB 9.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/10.3 MB 8.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.2/10.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.6/10.3 MB 7.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.9/10.3 MB 8.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.4/10.3 MB 7.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.7/10.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.0/10.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.4/10.3 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.6/10.3 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.0/10.3 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.5/10.3 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.9/10.3 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.3 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.5/10.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.8/10.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.1/10.3 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.4/10.3 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.7/10.3 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.8/10.3 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.1/10.3 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.4/10.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.8/10.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.1/10.3 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.4/10.3 MB 7.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.7/10.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.0/10.3 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.7/10.3 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.9/10.3 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.1/10.3 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.3/10.3 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.10.1-py3-none-any.whl (215 kB)\n",
      "   ---------------------------------------- 0.0/215.5 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 174.1/215.5 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  215.0/215.5 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 215.5/215.5 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading toml-0.9.6-py2.py3-none-any.whl (14 kB)\n",
      "Downloading enum34-1.1.10-py3-none-any.whl (11 kB)\n",
      "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "   ---------------------------------------- 0.0/159.9 kB ? eta -:--:--\n",
      "   -------------------------------------- - 153.6/159.9 kB 9.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 153.6/159.9 kB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 159.9/159.9 kB 1.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: scikit-learn\n",
      "  Building wheel for scikit-learn (setup.py): started\n",
      "  Building wheel for scikit-learn (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for scikit-learn\n",
      "Failed to build scikit-learn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1477 lines of output]\n",
      "      C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-ie5qbfo4\\scikit-learn_49c288a90eac47ea90663f7174f94cc3\\setup.py:12: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "        from pkg_resources import parse_version\n",
      "      Partial import of sklearn during the build process.\n",
      "      C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-ie5qbfo4\\scikit-learn_49c288a90eac47ea90663f7174f94cc3\\setup.py:123: DeprecationWarning:\n",
      "      \n",
      "        `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "        of the deprecation of `distutils` itself. It will be removed for\n",
      "        Python >= 3.12. For older Python versions it will remain present.\n",
      "        It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "        For more details, see:\n",
      "          https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "      \n",
      "      \n",
      "        from numpy.distutils.command.build_ext import build_ext  # noqa\n",
      "      INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "      INFO: C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um /Tctest_program.c /Foobjects\\test_program.obj\n",
      "      INFO: C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22621.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22621.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe\n",
      "      INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "      INFO: C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um /Tctest_program.c /Foobjects\\test_program.obj /openmp\n",
      "      INFO: C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22621.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22621.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe /openmp\n",
      "      Compiling sklearn\\__check_build\\_check_build.pyx because it changed.\n",
      "      Compiling sklearn\\preprocessing\\_csr_polynomial_expansion.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_dbscan_inner.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_hierarchical_fast.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_k_means_elkan.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_k_means_fast.pyx because it changed.\n",
      "      Compiling sklearn\\datasets\\_svmlight_format_fast.pyx because it changed.\n",
      "      Compiling sklearn\\decomposition\\_online_lda_fast.pyx because it changed.\n",
      "      Compiling sklearn\\decomposition\\_cdnmf_fast.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_gradient_boosting.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx because it changed.\n",
      "      Compiling sklearn\\feature_extraction\\_hashing_fast.pyx because it changed.\n",
      "      Compiling sklearn\\manifold\\_utils.pyx because it changed.\n",
      "      Compiling sklearn\\manifold\\_barnes_hut_tsne.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_pairwise_fast.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_ball_tree.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_kd_tree.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_dist_metrics.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_typedefs.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_quad_tree.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_tree.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_splitter.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_criterion.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_utils.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\sparsefuncs_fast.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_cython_blas.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\arrayfuncs.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\murmurhash.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\graph_shortest_path.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_fast_dict.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_openmp_helpers.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_seq_dataset.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_weight_vector.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_random.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_logistic_sigmoid.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_libsvm.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_liblinear.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_libsvm_sparse.pyx because it changed.\n",
      "      Compiling sklearn\\linear_model\\_cd_fast.pyx because it changed.\n",
      "      Compiling sklearn\\linear_model\\_sgd_fast.pyx because it changed.\n",
      "      Compiling sklearn\\linear_model\\_sag_fast.pyx because it changed.\n",
      "      Compiling sklearn\\_isotonic.pyx because it changed.\n",
      "      Partial import of sklearn during the build process.\n",
      "      Partial import of sklearn during the build process.\n",
      "      Partial import of sklearn during the build process.\n",
      "      Partial import of sklearn during the build process.\n",
      "      [ 1/50] Cythonizing sklearn\\__check_build\\_check_build.pyx\n",
      "      [ 2/50] Cythonizing sklearn\\_isotonic.pyx\n",
      "      [ 3/50] Cythonizing sklearn\\cluster\\_dbscan_inner.pyx\n",
      "      [ 4/50] Cythonizing sklearn\\cluster\\_hierarchical_fast.pyx\n",
      "      [ 5/50] Cythonizing sklearn\\cluster\\_k_means_elkan.pyx\n",
      "      warning: sklearn\\cluster\\_dbscan_inner.pyx:15:5: Only extern functions can throw C++ exceptions.\n",
      "      performance hint: sklearn\\cluster\\_k_means_elkan.pyx:20:5: Exception check on 'euclidean_dist' will always require the GIL to be acquired. Declare 'euclidean_dist' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [ 6/50] Cythonizing sklearn\\cluster\\_k_means_fast.pyx\n",
      "      [ 7/50] Cythonizing sklearn\\datasets\\_svmlight_format_fast.pyx\n",
      "      [ 8/50] Cythonizing sklearn\\decomposition\\_cdnmf_fast.pyx\n",
      "      [ 9/50] Cythonizing sklearn\\decomposition\\_online_lda_fast.pyx\n",
      "      [10/50] Cythonizing sklearn\\ensemble\\_gradient_boosting.pyx\n",
      "      [11/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [12/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [13/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx\n",
      "      [14/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx:92:5: Exception check on '_compute_softmax' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_compute_softmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_softmax' to allow an error code to be returned.\n",
      "      [15/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx\n",
      "      [16/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx\n",
      "      [17/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "      warning: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:18:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "      warning: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:259:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_loss.pyx:84:24: Exception check after calling '_compute_softmax' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_compute_softmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_softmax' to allow an error code to be returned.\n",
      "      [18/50] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:243:6: Exception check on '_build_histogram_naive' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_naive' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_naive' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:267:6: Exception check on '_subtract_histograms' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:291:6: Exception check on '_build_histogram' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:338:6: Exception check on '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:382:6: Exception check on '_build_histogram_root' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:435:6: Exception check on '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "      [19/50] Cythonizing sklearn\\feature_extraction\\_hashing_fast.pyx\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:155:60: Exception check after calling '_compute_histogram_brute_single_feature' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_compute_histogram_brute_single_feature' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_histogram_brute_single_feature' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:181:48: Exception check after calling '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:185:37: Exception check after calling '_build_histogram_root' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:190:43: Exception check after calling '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:194:32: Exception check after calling '_build_histogram' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:235:32: Exception check after calling '_subtract_histograms' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:404:58: Exception check after calling '_find_best_bin_to_split_left_to_right' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_find_best_bin_to_split_left_to_right' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_find_best_bin_to_split_left_to_right' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:413:62: Exception check after calling '_find_best_bin_to_split_right_to_left' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_find_best_bin_to_split_right_to_left' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_find_best_bin_to_split_right_to_left' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:418:70: Exception check after calling '_find_best_feature_to_split_helper' will always require the GIL to be acquired. Declare '_find_best_feature_to_split_helper' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [20/50] Cythonizing sklearn\\linear_model\\_cd_fast.pyx\n",
      "      [21/50] Cythonizing sklearn\\linear_model\\_sag_fast.pyx\n",
      "      [22/50] Cythonizing sklearn\\linear_model\\_sgd_fast.pyx\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:821:5: Exception check on 'l1penalty' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1201:5: Exception check on 'predict_sample64' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1248:5: Exception check on 'predict_sample32' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "      [23/50] Cythonizing sklearn\\manifold\\_barnes_hut_tsne.pyx\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:466:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:494:32: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:499:36: Exception check after calling '_dloss' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_dloss' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:502:45: Exception check after calling '_dloss' will always require the GIL to be acquired. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:797:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:825:32: Exception check after calling 'predict_sample32' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:830:36: Exception check after calling '_dloss' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_dloss' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:833:45: Exception check after calling '_dloss' will always require the GIL to be acquired. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1336:24: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1340:28: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1344:28: Exception check after calling '_dloss' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_dloss' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sag_fast.pyx:1347:39: Exception check after calling '_loss' will always require the GIL to be acquired. Declare '_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [24/50] Cythonizing sklearn\\manifold\\_utils.pyx\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:48:5: Exception check on 'fmax' will always require the GIL to be acquired. Declare 'fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:54:5: Exception check on 'fsign' will always require the GIL to be acquired. Declare 'fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:63:5: Exception check on 'abs_max' will always require the GIL to be acquired. Declare 'abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:75:5: Exception check on 'max' will always require the GIL to be acquired. Declare 'max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:87:5: Exception check on 'diff_abs_max' will always require the GIL to be acquired. Declare 'diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [25/50] Cythonizing sklearn\\metrics\\_pairwise_fast.pyx\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:669:31: Exception check after calling 'shuffle' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'shuffle' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'shuffle' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:671:28: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:679:25: Exception check after calling 'dot' will always require the GIL to be acquired. Declare 'dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:686:40: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:697:45: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:700:38: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:702:39: Exception check after calling '_dloss' will always require the GIL to be acquired. Declare '_dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:724:27: Exception check after calling 'scale' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'scale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'scale' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:726:25: Exception check after calling 'add' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'add' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:735:33: Exception check after calling 'add_average' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'add_average' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add_average' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_sgd_fast.pyx:742:29: Exception check after calling 'l1penalty' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "      [26/50] Cythonizing sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx\n",
      "      performance hint: sklearn\\manifold\\_barnes_hut_tsne.pyx:222:30: Exception check after calling 'summarize' will always require the GIL to be acquired. Declare 'summarize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [27/50] Cythonizing sklearn\\neighbors\\_ball_tree.pyx\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:613:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:621:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:683:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1196:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1205:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1782:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [28/50] Cythonizing sklearn\\neighbors\\_dist_metrics.pyx\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:19:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:29:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:38:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:42:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:65:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:68:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:75:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:77:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_ball_tree.pyx:109:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_ball_tree.pyx:125:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_ball_tree.pyx:136:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:19:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:29:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:38:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:42:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:65:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:68:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:75:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:77:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:294:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:302:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:334:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:338:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:415:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:419:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:422:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:425:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:451:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:463:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:466:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:469:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:492:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:513:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:544:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:552:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:555:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:558:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:599:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:611:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:614:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:617:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:664:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:684:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:687:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:690:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:713:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:735:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:758:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:784:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:814:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:838:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:863:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:888:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:912:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:936:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:960:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:988:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:998:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:1007:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:1010:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pyx:1107:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [29/50] Cythonizing sklearn\\neighbors\\_kd_tree.pyx\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:613:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:621:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:156:13: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:157:13: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:161:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:683:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:179:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:182:26: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:187:34: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:187:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:192:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:30: Exception check after calling '__pyx_fuse_0fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_0fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:198:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:208:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:209:21: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:217:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\neighbors\\_binary_tree.pxi:557:5: Exception check on 'dual_swap' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dual_swap' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:220:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:223:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:233:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:237:38: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:156:13: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:157:13: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:161:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:179:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:182:26: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:187:34: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:187:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:192:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:30: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:198:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:208:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:209:21: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:217:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:220:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:223:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:233:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:237:38: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1196:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1205:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:345:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:388:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:388:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      warning: sklearn\\neighbors\\_binary_tree.pxi:1782:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:429:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:431:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:434:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:437:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:446:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:448:54: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:345:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:388:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:388:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:429:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:431:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:434:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:437:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:446:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:448:54: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:547:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:560:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:577:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:582:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:584:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:593:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:604:37: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:547:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:555:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:560:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:577:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:582:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:584:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:593:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:604:37: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:696:24: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:700:25: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:715:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:718:24: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:720:24: Exception check after calling '__pyx_fuse_0_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:725:21: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:729:26: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:732:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:733:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:733:21: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:737:24: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:740:24: Exception check after calling '__pyx_fuse_0_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:745:37: Exception check after calling '__pyx_fuse_0diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:750:38: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:762:42: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:771:41: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:779:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:780:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:799:37: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:696:24: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:700:25: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:715:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:718:24: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:720:24: Exception check after calling '__pyx_fuse_1_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:725:21: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:729:26: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:732:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:733:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:733:21: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:737:24: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:740:24: Exception check after calling '__pyx_fuse_1_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:745:37: Exception check after calling '__pyx_fuse_1diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:750:38: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:762:42: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:771:41: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:779:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:780:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\linear_model\\_cd_fast.pyx:799:37: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      warning: sklearn\\neighbors\\_kd_tree.pyx:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_kd_tree.pyx:152:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [30/50] Cythonizing sklearn\\neighbors\\_quad_tree.pyx\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "              # determine number of levels in the tree, and from this\n",
      "              # the number of nodes in the tree.  This results in leaf nodes\n",
      "              # with numbers of points between leaf_size and 2 * leaf_size\n",
      "              self.n_levels = np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1\n",
      "              self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                                  ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\neighbors\\_binary_tree.pxi:1095:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'int')\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:137:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:326:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:485:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:579:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pyx:591:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:19:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:29:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:38:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:42:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:65:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:68:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:75:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_dist_metrics.pxd:77:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [31/50] Cythonizing sklearn\\neighbors\\_typedefs.pyx\n",
      "      performance hint: sklearn\\neighbors\\_binary_tree.pxi:557:5: Exception check on 'dual_swap' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dual_swap' to allow an error code to be returned.\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_ball_tree.pyx\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [32/50] Cythonizing sklearn\\preprocessing\\_csr_polynomial_expansion.pyx\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "              # determine number of levels in the tree, and from this\n",
      "              # the number of nodes in the tree.  This results in leaf nodes\n",
      "              # with numbers of points between leaf_size and 2 * leaf_size\n",
      "              self.n_levels = np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1\n",
      "              self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                                  ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\neighbors\\_binary_tree.pxi:1095:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'int')\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          def __cinit__(self, int n_dimensions, int verbose):\n",
      "              \"\"\"Constructor.\"\"\"\n",
      "              # Parameters of the tree\n",
      "              self.n_dimensions = n_dimensions\n",
      "              self.verbose = verbose\n",
      "              self.n_cells_per_cell = 2 ** self.n_dimensions\n",
      "                                        ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\neighbors\\_quad_tree.pyx:77:34: Cannot assign type 'double' to 'SIZE_t' (alias of 'int')\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              arr = PyArray_NewFromDescr(<PyTypeObject *> np.ndarray,\n",
      "                                         CELL_DTYPE, 1, shape,\n",
      "                                         strides, <void*> self.cells,\n",
      "                                         np.NPY_DEFAULT, None)\n",
      "              Py_INCREF(self)\n",
      "              arr.base = <PyObject*> self\n",
      "                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\neighbors\\_quad_tree.pyx:576:11: Assignment to a read-only property\n",
      "      [33/50] Cythonizing sklearn\\svm\\_liblinear.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              free_problem(problem)\n",
      "              free_parameter(param)\n",
      "              raise ValueError(error_msg)\n",
      "      \n",
      "          cdef BlasFunctions blas_functions\n",
      "          blas_functions.dot = _dot[double]\n",
      "                                   ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\svm\\_liblinear.pyx:55:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              free_parameter(param)\n",
      "              raise ValueError(error_msg)\n",
      "      \n",
      "          cdef BlasFunctions blas_functions\n",
      "          blas_functions.dot = _dot[double]\n",
      "          blas_functions.axpy = _axpy[double]\n",
      "                                     ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\svm\\_liblinear.pyx:56:31: Cannot assign type 'void (int, double, double *, int, double *, int) except * nogil' to 'axpy_func' (alias of 'void (*)(int, double, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              raise ValueError(error_msg)\n",
      "      \n",
      "          cdef BlasFunctions blas_functions\n",
      "          blas_functions.dot = _dot[double]\n",
      "          blas_functions.axpy = _axpy[double]\n",
      "          blas_functions.scal = _scal[double]\n",
      "                                     ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\svm\\_liblinear.pyx:57:31: Cannot assign type 'void (int, double, double *, int) except * nogil' to 'scal_func' (alias of 'void (*)(int, double, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "          cdef BlasFunctions blas_functions\n",
      "          blas_functions.dot = _dot[double]\n",
      "          blas_functions.axpy = _axpy[double]\n",
      "          blas_functions.scal = _scal[double]\n",
      "          blas_functions.nrm2 = _nrm2[double]\n",
      "                                     ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\svm\\_liblinear.pyx:58:31: Cannot assign type 'double (int, double *, int) except * nogil' to 'nrm2_func' (alias of 'double (*)(int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\svm\\_liblinear.pyx\n",
      "      [34/50] Cythonizing sklearn\\svm\\_libsvm.pyx\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_kd_tree.pyx\n",
      "      [35/50] Cythonizing sklearn\\svm\\_libsvm_sparse.pyx\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_quad_tree.pyx\n",
      "      [36/50] Cythonizing sklearn\\tree\\_criterion.pyx\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [37/50] Cythonizing sklearn\\tree\\_splitter.pyx\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [38/50] Cythonizing sklearn\\tree\\_tree.pyx\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      [39/50] Cythonizing sklearn\\tree\\_utils.pyx\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:56:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:82:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:90:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:97:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:281:76: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:346:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:373:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:400:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:742:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:783:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:794:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:805:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:1026:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:1074:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:1106:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pyx:1135:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:61:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:85:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pxd:90:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:57:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:58:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:59:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_criterion.pxd:60:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:188:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:218:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:285:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:601:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:1119:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_splitter.pyx:1348:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:284:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:433:76: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:683:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:695:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_tree.pyx:729:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:46:5: Exception check on '_init_split' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_init_split' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_init_split' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:479:5: Exception check on 'sort' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sort' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:486:5: Exception check on 'swap' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'swap' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:515:5: Exception check on 'introsort' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'introsort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'introsort' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:548:5: Exception check on 'sift_down' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sift_down' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sift_down' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:571:5: Exception check on 'heapsort' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapsort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapsort' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:963:5: Exception check on 'binary_search' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'binary_search' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:988:5: Exception check on 'extract_nnz_index_to_samples' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'extract_nnz_index_to_samples' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_index_to_samples' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:1028:5: Exception check on 'extract_nnz_binary_search' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'extract_nnz_binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_binary_search' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_splitter.pyx:1100:5: Exception check on 'sparse_swap' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sparse_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sparse_swap' to allow an error code to be returned.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:29:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:114:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:230:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:318:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:335:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:493:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pyx:507:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          if not is_samples_sorted[0]:\n",
      "              n_samples = end - start\n",
      "              memcpy(sorted_samples + start, samples + start,\n",
      "                     n_samples * sizeof(SIZE_t))\n",
      "              qsort(sorted_samples + start, n_samples, sizeof(SIZE_t),\n",
      "                    compare_SIZE_t)\n",
      "                    ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\tree\\_splitter.pyx:1056:14: Cannot assign type 'int (const void *, const void *) except? -1 nogil' to 'int (*)(const void *, const void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of 'compare_SIZE_t'.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:29:5: Exception check on 'safe_realloc' will always require the GIL to be acquired. Declare 'safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pxd:55:20: No exception value declared for 'rand_int' in pxd file.\n",
      "      Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "      Suggest adding an explicit exception value.\n",
      "      performance hint: sklearn\\tree\\_utils.pxd:59:24: No exception value declared for 'rand_uniform' in pxd file.\n",
      "      Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "      Suggest adding an explicit exception value.\n",
      "      performance hint: sklearn\\tree\\_utils.pxd:63:15: No exception value declared for 'log' in pxd file.\n",
      "      Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "      Suggest adding an explicit exception value.\n",
      "      warning: sklearn\\tree\\_utils.pxd:49:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:87:61: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:119:56: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:137:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:139:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:160:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\tree\\_utils.pxd:161:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:76:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:95:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:98:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:99:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      warning: sklearn\\neighbors\\_quad_tree.pxd:100:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:169:30: Exception check after calling 'children_impurity' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'children_impurity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'children_impurity' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:200:30: Exception check after calling 'children_impurity' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'children_impurity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'children_impurity' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:537:44: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:572:49: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:577:50: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1068:89: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1097:74: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1099:62: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1126:75: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1128:63: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1168:70: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1184:69: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1246:74: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_criterion.pyx:1258:75: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      [40/50] Cythonizing sklearn\\utils\\_cython_blas.pyx\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\tree\\_splitter.pyx\n",
      "      [41/50] Cythonizing sklearn\\utils\\_fast_dict.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "              # Initial capacity\n",
      "              cdef int init_capacity\n",
      "      \n",
      "              if tree.max_depth <= 10:\n",
      "                  init_capacity = (2 ** (tree.max_depth + 1)) - 1\n",
      "                                                              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\tree\\_tree.pyx:162:56: Cannot assign type 'double' to 'int'\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              shape[1] = <np.npy_intp> self.n_outputs\n",
      "              shape[2] = <np.npy_intp> self.max_n_classes\n",
      "              cdef np.ndarray arr\n",
      "              arr = np.PyArray_SimpleNewFromData(3, shape, np.NPY_DOUBLE, self.value)\n",
      "              Py_INCREF(self)\n",
      "              arr.base = <PyObject*> self\n",
      "                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\tree\\_tree.pyx:1103:11: Assignment to a read-only property\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              arr = PyArray_NewFromDescr(<PyTypeObject *> np.ndarray,\n",
      "                                         <np.dtype> NODE_DTYPE, 1, shape,\n",
      "                                         strides, <void*> self.nodes,\n",
      "                                         np.NPY_DEFAULT, None)\n",
      "              Py_INCREF(self)\n",
      "              arr.base = <PyObject*> self\n",
      "                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\tree\\_tree.pyx:1124:11: Assignment to a read-only property\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:20:5: Exception check on '_dot' will always require the GIL to be acquired. Declare '_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:127:24: Exception check after calling '__pyx_fuse_9safe_realloc' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_9safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:205:27: Exception check after calling 'heapify_up' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapify_up' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_up' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:225:29: Exception check after calling 'heapify_down' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapify_down' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_down' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:243:24: Exception check after calling '__pyx_fuse_10safe_realloc' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_10safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:259:23: Exception check after calling 'heapify_up' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapify_up' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_up' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:281:29: Exception check after calling 'heapify_down' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'heapify_down' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'heapify_down' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:326:20: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:349:24: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:491:32: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:516:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:517:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:520:47: Exception check after calling 'update_median_parameters_post_push' will always require the GIL to be acquired. Declare 'update_median_parameters_post_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:531:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:551:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:554:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:560:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:563:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:573:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:574:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:576:42: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:577:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:588:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:589:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:592:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:595:39: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:596:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:607:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:614:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:635:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:638:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:645:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:648:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:656:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:657:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\tree\\_utils.pyx:660:52: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:33:5: Exception check on '_asum' will always require the GIL to be acquired. Declare '_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:45:5: Exception check on '_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:58:5: Exception check on '_nrm2' will always require the GIL to be acquired. Declare '_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:70:5: Exception check on '_copy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_copy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:82:5: Exception check on '_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_scal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:94:5: Exception check on '_rotg' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_rotg' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rotg' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:107:5: Exception check on '_rot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_rot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rot' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:124:5: Exception check on '_gemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:153:5: Exception check on '_ger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_ger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:183:5: Exception check on '_gemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemm' to allow an error code to be returned.\n",
      "      [42/50] Cythonizing sklearn\\utils\\_logistic_sigmoid.pyx\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\tree\\_tree.pyx\n",
      "      [43/50] Cythonizing sklearn\\utils\\_openmp_helpers.pyx\n",
      "      warning: sklearn\\utils\\_openmp_helpers.pyx:1:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "      warning: sklearn\\utils\\_openmp_helpers.pyx:44:4: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "      [44/50] Cythonizing sklearn\\utils\\_random.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              dec(end)\n",
      "              # Construct our arguments\n",
      "              cdef pair[ITYPE_t, DTYPE_t] args\n",
      "              args.first = key\n",
      "              args.second = value\n",
      "              self.my_map.insert(end, args)\n",
      "                                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_fast_dict.pyx:138:27: Cannot assign type 'iterator' to 'const_iterator'\n",
      "      [45/50] Cythonizing sklearn\\utils\\_seq_dataset.pyx\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\utils\\_fast_dict.pyx\n",
      "      [46/50] Cythonizing sklearn\\utils\\_weight_vector.pyx\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:80:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:81:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:117:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:118:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:405:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:406:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:442:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: sklearn\\utils\\_seq_dataset.pyx:443:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "      [47/50] Cythonizing sklearn\\utils\\arrayfuncs.pyx\n",
      "      [48/50] Cythonizing sklearn\\utils\\graph_shortest_path.pyx\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:24:19: Exception check after calling 'sdot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sdot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:26:19: Exception check after calling 'ddot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'ddot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:36:20: Exception check after calling 'sasum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sasum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:38:20: Exception check after calling 'dasum' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dasum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:49:13: Exception check after calling 'saxpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'saxpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'saxpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:51:13: Exception check after calling 'daxpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'daxpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'daxpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:61:20: Exception check after calling 'snrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'snrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:63:20: Exception check after calling 'dnrm2' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dnrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:73:13: Exception check after calling 'scopy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'scopy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'scopy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:75:13: Exception check after calling 'dcopy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dcopy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dcopy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:85:13: Exception check after calling 'sscal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sscal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sscal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:87:13: Exception check after calling 'dscal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dscal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dscal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:97:13: Exception check after calling 'srotg' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'srotg' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'srotg' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:99:13: Exception check after calling 'drotg' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'drotg' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'drotg' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:111:12: Exception check after calling 'srot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'srot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'srot' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:113:12: Exception check after calling 'drot' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'drot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'drot' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:132:17: Exception check after calling 'sgemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sgemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sgemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:137:17: Exception check after calling 'sgemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sgemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sgemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:134:17: Exception check after calling 'dgemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dgemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dgemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:139:17: Exception check after calling 'dgemv' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dgemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dgemv' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:158:16: Exception check after calling 'sger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:163:16: Exception check after calling 'sger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:160:16: Exception check after calling 'dger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:165:16: Exception check after calling 'dger' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dger' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:192:17: Exception check after calling 'sgemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sgemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sgemm' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:199:17: Exception check after calling 'sgemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'sgemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sgemm' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:195:17: Exception check after calling 'dgemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dgemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dgemm' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_cython_blas.pyx:202:17: Exception check after calling 'dgemm' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'dgemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dgemm' to allow an error code to be returned.\n",
      "      [49/50] Cythonizing sklearn\\utils\\murmurhash.pyx\n",
      "      [50/50] Cythonizing sklearn\\utils\\sparsefuncs_fast.pyx\n",
      "      performance hint: sklearn\\utils\\_weight_vector.pyx:169:29: Exception check after calling 'reset_wscale' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare 'reset_wscale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'reset_wscale' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_weight_vector.pyx:174:17: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_weight_vector.pyx:176:17: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "      performance hint: sklearn\\utils\\_weight_vector.pyx:180:13: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "      multiprocessing.pool.RemoteTraceback:\n",
      "      \"\"\"\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "          result = (True, func(*args, **kwds))\n",
      "                          ^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 48, in mapstar\n",
      "          return list(map(*args))\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_ball_tree.pyx\n",
      "      \"\"\"\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-ie5qbfo4\\scikit-learn_49c288a90eac47ea90663f7174f94cc3\\setup.py\", line 303, in <module>\n",
      "          setup_package()\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-ie5qbfo4\\scikit-learn_49c288a90eac47ea90663f7174f94cc3\\setup.py\", line 299, in setup_package\n",
      "          setup(**metadata)\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 136, in setup\n",
      "          config = configuration()\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-ie5qbfo4\\scikit-learn_49c288a90eac47ea90663f7174f94cc3\\setup.py\", line 182, in configuration\n",
      "          config.add_subpackage('sklearn')\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1050, in add_subpackage\n",
      "          config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1016, in get_subpackage\n",
      "          config = self._get_configuration_from_setup_py(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 958, in _get_configuration_from_setup_py\n",
      "          config = setup_module.configuration(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-ie5qbfo4\\scikit-learn_49c288a90eac47ea90663f7174f94cc3\\sklearn\\setup.py\", line 86, in configuration\n",
      "          cythonize_extensions(top_path, config)\n",
      "        File \"C:\\Users\\nikhi\\AppData\\Local\\Temp\\pip-install-ie5qbfo4\\scikit-learn_49c288a90eac47ea90663f7174f94cc3\\sklearn\\_build_utils\\__init__.py\", line 75, in cythonize_extensions\n",
      "          config.ext_modules = cythonize(\n",
      "                               ^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1145, in cythonize\n",
      "          result.get(99999)  # seconds\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\nikhi\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 774, in get\n",
      "          raise self._value\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_ball_tree.pyx\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-learn\n",
      "ERROR: Could not build wheels for scikit-learn, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting NiaPy"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\nikhi\\anaconda3\\Lib\\site-packages\\~atplotlib'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading niapy-2.1.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting matplotlib<4.0.0,>=3.8.0 (from NiaPy)\n",
      "  Downloading matplotlib-3.8.4-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from NiaPy) (1.26.4)\n",
      "Requirement already satisfied: openpyxl<4.0.0,>=3.1.2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from NiaPy) (3.1.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from NiaPy) (2.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->NiaPy) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->NiaPy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->NiaPy) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->NiaPy) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->NiaPy) (23.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->NiaPy) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->NiaPy) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.0->NiaPy) (2.8.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from openpyxl<4.0.0,>=3.1.2->NiaPy) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=2.1.1->NiaPy) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=2.1.1->NiaPy) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.8.0->NiaPy) (1.16.0)\n",
      "Downloading niapy-2.1.0-py3-none-any.whl (183 kB)\n",
      "   ---------------------------------------- 0.0/183.9 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 92.2/183.9 kB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 174.1/183.9 kB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 174.1/183.9 kB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 174.1/183.9 kB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 174.1/183.9 kB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- 183.9/183.9 kB 793.0 kB/s eta 0:00:00\n",
      "Downloading matplotlib-3.8.4-cp311-cp311-win_amd64.whl (7.7 MB)\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/7.7 MB 3.1 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/7.7 MB 3.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/7.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.1/7.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.5/7.7 MB 5.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.8/7.7 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.1/7.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.5/7.7 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.8/7.7 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.3/7.7 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.8/7.7 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.2/7.7 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.5/7.7 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.8/7.7 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.1/7.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.4/7.7 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.8/7.7 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.1/7.7 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.5/7.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.8/7.7 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.3/7.7 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.7/7.7 MB 5.2 MB/s eta 0:00:00\n",
      "Installing collected packages: matplotlib, NiaPy\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.1\n",
      "    Uninstalling matplotlib-3.7.1:\n",
      "      Successfully uninstalled matplotlib-3.7.1\n",
      "Successfully installed NiaPy-2.1.0 matplotlib-3.8.4\n",
      "Requirement already satisfied: algorithms in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (0.1.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn_nature_inspired_algorithms==0.4.3\n",
    "! pip install NiaPy\n",
    "! pip install algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "I9lhabzRqzwq"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test, modelname):\n",
    "    y_pred1 = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred1)\n",
    "    recall = recall_score(y_test, y_pred1)\n",
    "    f1score = f1_score(y_test, y_pred1)\n",
    "    rocauc = roc_auc_score(y_test, y_pred1)\n",
    "    logloss = log_loss(y_test, y_pred1)\n",
    "    accuracy = accuracy_score(y_test, y_pred1)\n",
    "\n",
    "    df_model = pd.DataFrame(\n",
    "        {\n",
    "            \"model\": [modelname],\n",
    "            \"accuracy\": [accuracy],\n",
    "            \"precision\": [precision],\n",
    "            \"recall\": [recall],\n",
    "            \"f1score\": [f1score],\n",
    "            \"rocauc\": [rocauc],\n",
    "            \"logloss\": [logloss],\n",
    "            \"timetaken\": [time1],\n",
    "        }\n",
    "    )\n",
    "    return df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8yl1vg8DN6R",
    "outputId": "4418e80e-7153-49c7-f9ed-67d4cb49414b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(200, 2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "param_grid_rt = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"bootstrap\": bootstrap,\n",
    "}\n",
    "print(param_grid_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxbaIOToqEw5"
   },
   "source": [
    "NATURE INSPIRIED SEARCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 3 candidates, which might total in 9 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 1/5 finished\n",
      "Run 2/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 2/5 finished\n",
      "Run 3/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 3/5 finished\n",
      "Run 4/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 4/5 finished\n",
      "Run 5/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 5/5 finished\n",
      "Optimization finished, 3 candidates were fitted (totalling 9 fits)\n",
      "Time taken: 7.678664684295654 seconds\n",
      "           model  accuracy  precision    recall   f1score    rocauc   logloss  \\\n",
      "0  Random Forest  0.753247       0.66  0.611111  0.634615  0.720556  8.893888   \n",
      "\n",
      "      timetaken  \n",
      "0  1.713840e+09  \n"
     ]
    }
   ],
   "source": [
    "from sklearn_nature_inspired_algorithms.model_selection import (\n",
    "    NatureInspiredSearchCV,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "# Define the parameter grid for NatureInspiredSearchCV\n",
    "param_grid_rt = {\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]  # Valid options for max_features\n",
    "}\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "clf_1 = RandomForestClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV\n",
    "nia_search = NatureInspiredSearchCV(\n",
    "    clf_1,\n",
    "    param_grid_rt,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm=\"ba\",  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    error_score=\"raise\",  # Raise an error if fitting fails\n",
    ")\n",
    "\n",
    "# Fit NatureInspiredSearchCV\n",
    "nia_search.fit(X_train, y_train)\n",
    "\n",
    "# End the timer and print elapsed time\n",
    "print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "\n",
    "# Get the best estimator found during the search\n",
    "best_estimator = nia_search.best_estimator_\n",
    "\n",
    "# Evaluate the best estimator\n",
    "model1 = evaluate(best_estimator, X_test, y_test, \"Random Forest\")\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vG5IJX6fo_87",
    "outputId": "061ccd9d-0041-41ce-a25c-c85285c7e8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5l36OJauk_z",
    "outputId": "21ea6073-ae47-40d7-9edf-90227481dc1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et = ExtraTreesClassifier()\n",
    "print(et.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xN83KMC-urht",
    "outputId": "57f2fe25-72db-4083-9ebf-50ea284df428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "param_grid_et = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"bootstrap\": bootstrap,\n",
    "}\n",
    "print(param_grid_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 3 candidates, which might total in 9 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 1/5 finished\n",
      "Run 2/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 2/5 finished\n",
      "Run 3/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 3/5 finished\n",
      "Run 4/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 4/5 finished\n",
      "Run 5/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 5/5 finished\n",
      "Optimization finished, 3 candidates were fitted (totalling 9 fits)\n",
      "Time taken: 6.929619073867798 seconds\n",
      "        model  accuracy  precision    recall   f1score    rocauc    logloss  \\\n",
      "0  Extra Tree  0.714286   0.604167  0.537037  0.568627  0.673519  10.298187   \n",
      "\n",
      "   timetaken  \n",
      "0   6.932276  \n"
     ]
    }
   ],
   "source": [
    "from sklearn_nature_inspired_algorithms.model_selection import (\n",
    "    NatureInspiredSearchCV,\n",
    ")\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import time\n",
    "\n",
    "# Define the parameter grid for ExtraTreesClassifier\n",
    "param_grid_et = {\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"]  # Valid options for max_features\n",
    "}\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Initialize the ExtraTreesClassifier\n",
    "clf_2 = ExtraTreesClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV for ExtraTreesClassifier\n",
    "nia_search2 = NatureInspiredSearchCV(\n",
    "    clf_2,\n",
    "    param_grid_et,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm=\"ba\",  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    error_score=\"raise\",  # Raise an error if fitting fails\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit NatureInspiredSearchCV for ExtraTreesClassifier\n",
    "    nia_search2.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best estimator found during the search for ExtraTreesClassifier\n",
    "    ba_et = nia_search2.best_estimator_\n",
    "\n",
    "    # Evaluate the best estimator\n",
    "    model3 = evaluate(ba_et, X_test, y_test, \"Extra Tree\")\n",
    "\n",
    "    # Print the time taken for the fitting process\n",
    "    print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "\n",
    "    # Update the time taken in the model evaluation\n",
    "    model3.timetaken[0] = time.time() - time1\n",
    "\n",
    "    # Print the evaluation results\n",
    "    print(model3)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(\"Fitting failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lXMlBR4urnd",
    "outputId": "e8c0aeef-4dbb-4632-9538-e93537ace647"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting at most 2 candidates\n",
      "Optimization finished, 2 candidates were fitted\n",
      "Time taken: 17.54552674293518 seconds\n",
      "        model  accuracy  precision    recall   f1score    rocauc    logloss  \\\n",
      "0  Extra Tree  0.720779   0.607843  0.574074  0.590476  0.687037  10.064137   \n",
      "\n",
      "   timetaken  \n",
      "0  17.545527  \n",
      "CPU times: total: 13.2 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "import time\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Define the parameter grid with valid options for 'max_features'\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [110],\n",
    "    'max_features': ['sqrt', 'log2'],  # Valid options for 'max_features'\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [5],\n",
    "    'n_estimators': [800]\n",
    "}\n",
    "\n",
    "# Initialize the ExtraTreesClassifier\n",
    "clf_2 = ExtraTreesClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV for ExtraTreesClassifier\n",
    "nia_search2 = NatureInspiredSearchCV(\n",
    "    clf_2,\n",
    "    param_grid,\n",
    "    algorithm='ba',  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit NatureInspiredSearchCV for ExtraTreesClassifier\n",
    "    nia_search2.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator found during the search for ExtraTreesClassifier\n",
    "    ba_et = nia_search2.best_estimator_\n",
    "    \n",
    "    # Evaluate the best estimator\n",
    "    model3 = evaluate(ba_et, X_test, y_test, 'Extra Tree')\n",
    "    \n",
    "    # Print the time taken for the fitting process\n",
    "    print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "    \n",
    "    # Update the time taken in the model evaluation\n",
    "    model3.timetaken[0] = time.time() - time1\n",
    "    \n",
    "    # Print the evaluation results\n",
    "    print(model3)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(\"Fitting failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThL-VQlNlnBW",
    "outputId": "d1cb66ca-b743-498f-a7db-154d3a7fa94d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 110,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 800}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hc6wOJdxgxH5",
    "outputId": "ff6ca357-fed1-4aad-e5eb-16b1c4d2794b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "print(dtc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLAohyaxgxLR",
    "outputId": "d091d9d9-44ad-497d-871c-953e054d1525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': ['auto', 'sqrt'], 'max_depth': [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210], 'min_samples_split': [2, 5, 10, 15], 'min_samples_leaf': [2, 4, 10]}\n"
     ]
    }
   ],
   "source": [
    "class_weight = [int(x) for x in np.linspace(start=10, stop=100, num=10)]\n",
    "class_weight.append(None)\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 210, num=11)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "# Create the random grid\n",
    "param_grid_dt = {  #'class_weight': class_weight,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "}\n",
    "print(param_grid_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9QPp2hRiETw",
    "outputId": "ab90288c-3f2f-4582-e7e0-f87eb89526e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 3 candidates, which might total in 9 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 1/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 1/5 finished\n",
      "Run 2/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 2/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 2/5 finished\n",
      "Run 3/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 3/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 3/5 finished\n",
      "Run 4/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 4/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 4/5 finished\n",
      "Run 5/5, Iteration 1/100 | Stagnation 0/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 2/100 | Stagnation 1/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 3/100 | Stagnation 2/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 4/100 | Stagnation 3/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 5/100 | Stagnation 4/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 6/100 | Stagnation 5/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 7/100 | Stagnation 6/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 8/100 | Stagnation 7/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 9/100 | Stagnation 8/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 10/100 | Stagnation 9/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 11/100 | Stagnation 10/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 12/100 | Stagnation 11/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 13/100 | Stagnation 12/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 14/100 | Stagnation 13/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 15/100 | Stagnation 14/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 16/100 | Stagnation 15/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 17/100 | Stagnation 16/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 18/100 | Stagnation 17/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 19/100 | Stagnation 18/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 20/100 | Stagnation 19/20 | There were 3 candidates trained until now\n",
      "Run 5/5, Iteration 21/100 | Stagnation 20/20 | There were 3 candidates trained until now\n",
      "Run 5/5 finished\n",
      "Optimization finished, 3 candidates were fitted (totalling 9 fits)\n",
      "Time taken: 0.20963454246520996 seconds\n",
      "           model  accuracy  precision    recall   f1score    rocauc  \\\n",
      "0  Decision Tree  0.681818   0.545455  0.555556  0.550459  0.652778   \n",
      "\n",
      "     logloss  timetaken  \n",
      "0  11.468435   0.209635  \n",
      "CPU times: total: 188 ms\n",
      "Wall time: 210 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "import time\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Define the parameter grid with valid options for 'max_features'\n",
    "param_grid_dt = {\n",
    "    'max_features': ['sqrt', 'log2', None]  # Valid options for 'max_features'\n",
    "}\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "clf_3 = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV for DecisionTreeClassifier\n",
    "nia_search3 = NatureInspiredSearchCV(\n",
    "    clf_3,\n",
    "    param_grid_dt,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba',  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit NatureInspiredSearchCV for DecisionTreeClassifier\n",
    "    nia_search3.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator found during the search for DecisionTreeClassifier\n",
    "    ba_dt = nia_search3.best_estimator_\n",
    "    \n",
    "    # Evaluate the best estimator\n",
    "    model4 = evaluate(ba_dt, X_test, y_test, 'Decision Tree')\n",
    "    \n",
    "    # Print the time taken for the fitting process\n",
    "    print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "    \n",
    "    # Update the time taken in the model evaluation\n",
    "    model4.timetaken[0] = time.time() - time1\n",
    "    \n",
    "    # Print the evaluation results\n",
    "    print(model4)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(\"Fitting failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5Ig_jHKkcBt",
    "outputId": "a2c3fda6-b032-44b3-d3b8-89c91295ea0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzVp4BHak6RF",
    "outputId": "2dd9fe46-3739-44b5-dac4-71e3ff8faa2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 1 candidates, which might total in 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 1/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 1/5 finished\n",
      "Run 2/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 2/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 2/5 finished\n",
      "Run 3/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 3/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 3/5 finished\n",
      "Run 4/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 4/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 4/5 finished\n",
      "Run 5/5, Iteration 1/200 | Stagnation 0/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 2/200 | Stagnation 1/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 3/200 | Stagnation 2/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 4/200 | Stagnation 3/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 5/200 | Stagnation 4/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 6/200 | Stagnation 5/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 7/200 | Stagnation 6/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 8/200 | Stagnation 7/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 9/200 | Stagnation 8/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 10/200 | Stagnation 9/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 11/200 | Stagnation 10/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 12/200 | Stagnation 11/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 13/200 | Stagnation 12/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 14/200 | Stagnation 13/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 15/200 | Stagnation 14/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 16/200 | Stagnation 15/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 17/200 | Stagnation 16/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 18/200 | Stagnation 17/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 19/200 | Stagnation 18/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 20/200 | Stagnation 19/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 21/200 | Stagnation 20/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 22/200 | Stagnation 21/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 23/200 | Stagnation 22/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 24/200 | Stagnation 23/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 25/200 | Stagnation 24/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 26/200 | Stagnation 25/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 27/200 | Stagnation 26/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 28/200 | Stagnation 27/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 29/200 | Stagnation 28/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 30/200 | Stagnation 29/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 31/200 | Stagnation 30/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 32/200 | Stagnation 31/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 33/200 | Stagnation 32/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 34/200 | Stagnation 33/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 35/200 | Stagnation 34/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 36/200 | Stagnation 35/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 37/200 | Stagnation 36/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 38/200 | Stagnation 37/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 39/200 | Stagnation 38/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 40/200 | Stagnation 39/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 41/200 | Stagnation 40/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 42/200 | Stagnation 41/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 43/200 | Stagnation 42/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 44/200 | Stagnation 43/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 45/200 | Stagnation 44/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 46/200 | Stagnation 45/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 47/200 | Stagnation 46/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 48/200 | Stagnation 47/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 49/200 | Stagnation 48/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 50/200 | Stagnation 49/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 51/200 | Stagnation 50/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 52/200 | Stagnation 51/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 53/200 | Stagnation 52/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 54/200 | Stagnation 53/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 55/200 | Stagnation 54/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 56/200 | Stagnation 55/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 57/200 | Stagnation 56/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 58/200 | Stagnation 57/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 59/200 | Stagnation 58/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 60/200 | Stagnation 59/60 | There were 1 candidates trained until now\n",
      "Run 5/5, Iteration 61/200 | Stagnation 60/60 | There were 1 candidates trained until now\n",
      "Run 5/5 finished\n",
      "Optimization finished, 1 candidates were fitted (totalling 3 fits)\n",
      "Time taken: 0.35559701919555664 seconds\n",
      "           model  accuracy  precision    recall   f1score    rocauc   logloss  \\\n",
      "0  Decision Tree  0.727273   0.676471  0.425926  0.522727  0.657963  9.830087   \n",
      "\n",
      "   timetaken  \n",
      "0   0.355597  \n",
      "CPU times: total: 250 ms\n",
      "Wall time: 365 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "import time\n",
    "\n",
    "# Start the timer\n",
    "time1 = time.time()\n",
    "\n",
    "# Define the parameter grid with valid options for 'max_features'\n",
    "param_grid = {\n",
    "    'max_depth': [115],\n",
    "    'max_features': [None],  # Use None instead of 'auto'\n",
    "    'min_samples_leaf': [4],\n",
    "    'min_samples_split': [10],\n",
    "}\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "clf_3 = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV for DecisionTreeClassifier\n",
    "nia_search3 = NatureInspiredSearchCV(\n",
    "    clf_3,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba',  # Bat algorithm\n",
    "    population_size=150,\n",
    "    max_n_gen=200,\n",
    "    max_stagnating_gen=60,\n",
    "    runs=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit NatureInspiredSearchCV for DecisionTreeClassifier\n",
    "    nia_search3.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator found during the search for DecisionTreeClassifier\n",
    "    ba_dt = nia_search3.best_estimator_\n",
    "    \n",
    "    # Evaluate the best estimator\n",
    "    model3 = evaluate(ba_dt, X_test, y_test, 'Decision Tree')\n",
    "    \n",
    "    # Print the time taken for the fitting process\n",
    "    print(\"Time taken:\", time.time() - time1, \"seconds\")\n",
    "    \n",
    "    # Update the time taken in the model evaluation\n",
    "    model3.timetaken[0] = time.time() - time1\n",
    "    \n",
    "    # Print the evaluation results\n",
    "    print(model3)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(\"Fitting failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9bGSBfikxWM",
    "outputId": "3bdf15bf-9dc2-4907-c4b7-03f91b2118d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 115,\n",
       " 'max_features': None,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBGWTINKo__K",
    "outputId": "4f4eb11d-cc64-4528-cb82-dc44f0e0a332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "print(lr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPIJy262pACh",
    "outputId": "027d8648-73f0-422e-e3c3-ee44350c03ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'C': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0]}\n"
     ]
    }
   ],
   "source": [
    "max_iter = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "C = [float(x) for x in np.linspace(start=1, stop=20, num=20)]\n",
    "solver = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "class_weight = [int(x) for x in np.linspace(1, 10, num=10)]\n",
    "class_weight.append(None)\n",
    "n_jobs = [int(x) for x in np.linspace(1, 10, num=10)]\n",
    "# n_jobs.append(None)\n",
    "intercept_scaling = [1, 2, 4]\n",
    "verbose = [0, 1, 2, 3]\n",
    "dual = [True, False]\n",
    "multi_class = [\"auto\", \"ovr\", \"multinomial\"]\n",
    "tol = [0.00001, 0.0001, 0.001, 0.01, 0.1, 0, 1]\n",
    "# Create the random grid\n",
    "param_grid_lr = {\n",
    "    \"max_iter\": max_iter,\n",
    "    #'class_weight': class_weight,\n",
    "    \"solver\": solver,\n",
    "    #'intercept_scaling': intercept_scaling,\n",
    "    #'dual': dual,\n",
    "    #'n_jobs' : n_jobs,\n",
    "    #'verbose' : verbose,\n",
    "    \"C\": C,\n",
    "    #'tol' : tol\n",
    "    #'multi_class' : multi_class\n",
    "}\n",
    "print(param_grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJdP3H9Frt6k",
    "outputId": "319c4981-baa8-4ce7-8433-104838cd5658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 1000 candidates, which might total in 3000 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 38 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 50 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 60 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 67 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 71 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 78 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 86 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 95 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 102 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 117 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 127 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 132 candidates trained until now\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 132 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 136 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 143 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 145 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 147 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 148 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 152 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 155 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 158 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 180 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 188 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 191 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 194 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 198 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 202 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 205 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 210 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 214 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 217 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 222 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 230 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 234 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 243 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 246 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 248 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 251 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 252 candidates trained until now\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 252 candidates trained until now\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 252 candidates trained until now\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 252 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 273 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 281 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 286 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 293 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 295 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 299 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 305 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 311 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 316 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 322 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 325 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 329 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 333 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 335 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 338 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 343 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 353 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 358 candidates trained until now\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 358 candidates trained until now\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 358 candidates trained until now\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 358 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 358 candidates were fitted (totalling 1074 fits)\n",
      "Bat model\n",
      "Logistic Regression\n",
      "                 model  accuracy  precision    recall  f1score    rocauc  \\\n",
      "0  Logistic Regression  0.701299   0.583333  0.518519  0.54902  0.659259   \n",
      "\n",
      "     logloss  timetaken  \n",
      "0  10.766286  23.913505  \n",
      "CPU times: total: 3.7 s\n",
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "time1 = time.time()\n",
    "clf_1 = LogisticRegression()\n",
    "\n",
    "nia_search1 = NatureInspiredSearchCV(\n",
    "    clf_1,\n",
    "    param_grid_lr,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba', #  bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    \n",
    "    # or any number if you want same results on each run\n",
    ")\n",
    "\n",
    "\n",
    "nia_search1.fit(X_train, y_train)\n",
    "print(\"Bat model\")\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "\n",
    "ba_lr= nia_search1.best_estimator_\n",
    "model2=evaluate(ba_lr,  X_test,  y_test, 'Logistic Regression')\n",
    "model2.timetaken[0] = time.time() - time1\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95alnjqzrt_d",
    "outputId": "94d221ce-e0fd-4a61-882c-d14e1cff4a70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1400, 'solver': 'newton-cg', 'C': 20.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nia_search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YH6lW7uJr2lD",
    "outputId": "5c3d7f9b-b4d8-44f6-f80c-f06c0ef28e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kn = KNeighborsClassifier()\n",
    "print(kn.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMmK02-wr5a8",
    "outputId": "5c5087e9-2663-47ee-b224-aa1f6c9d455b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': [100, 111, 122, 133, 144, 155, 166, 177, 188, 200], 'p': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n"
     ]
    }
   ],
   "source": [
    "leaf_size = [int(x) for x in np.linspace(start=100, stop=200, num=10)]\n",
    "# n_neighbors=[int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "# n_neighbors.append(None)\n",
    "# Number of features to consider at every split\n",
    "algorithm = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "# Maximum number of levels in tree\n",
    "p = [int(x) for x in np.linspace(1, 20, num=20)]\n",
    "param_grid_kn = {\n",
    "    \"leaf_size\": leaf_size,\n",
    "    \"p\": p,\n",
    "    \"algorithm\": algorithm,\n",
    "    #'n_neighbors' : n_neighbors,\n",
    "}\n",
    "print(param_grid_kn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFNyXstJr5eg",
    "outputId": "8accbc61-b614-41db-9b8b-25a1409c8b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 800 candidates, which might total in 2400 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "An error occurred during fitting: 'NoneType' object has no attribute 'copy'\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "import time\n",
    "\n",
    "time1 = time.time()\n",
    "\n",
    "clf_4 = KNeighborsClassifier()\n",
    "\n",
    "nia_search4 = NatureInspiredSearchCV(\n",
    "    clf_4,\n",
    "    param_grid_kn,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba',\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "try:\n",
    "    nia_search4.fit(X_train, y_train)\n",
    "    ba_kn = nia_search4.best_estimator_\n",
    "    model4 = evaluate(ba_kn, X_test, y_test, 'KNN')\n",
    "    model4.timetaken[0] = time.time() - time1\n",
    "    print(model4)\n",
    "except AttributeError as e:\n",
    "    print(\"An error occurred during fitting:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGw4cjQXufWc",
    "outputId": "1ee9629b-257e-4d6b-d348-527fffad4997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 6 candidates, which might total in 18 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 6 candidates trained until now\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 6 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 6 candidates trained until now\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 6 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 6 candidates trained until now\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 6 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 6 candidates were fitted (totalling 18 fits)\n",
      "Bat model\n",
      "KNN\n",
      "  model  accuracy  precision    recall   f1score    rocauc    logloss  \\\n",
      "0   KNN  0.688312       0.56  0.518519  0.538462  0.649259  11.234385   \n",
      "\n",
      "   timetaken  \n",
      "0   0.647595  \n"
     ]
    }
   ],
   "source": [
    "from sklearn_nature_inspired_algorithms.model_selection import (\n",
    "    NatureInspiredSearchCV,\n",
    ")\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the reduced parameter grid\n",
    "param_grid = {\"leaf_size\": [30, 60, 90], \"p\": [1, 2]}\n",
    "\n",
    "# Start timing\n",
    "time1 = time.time()\n",
    "\n",
    "# Create the KNeighborsClassifier instance\n",
    "clf_4 = KNeighborsClassifier()\n",
    "\n",
    "# Initialize NatureInspiredSearchCV\n",
    "nia_search4 = NatureInspiredSearchCV(\n",
    "    clf_4,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm=\"ba\",  # Bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the search\n",
    "nia_search4.fit(X_train, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Bat model\")\n",
    "print(\"KNN\")\n",
    "\n",
    "# Retrieve the best estimator\n",
    "ba_kn = nia_search4.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "model4 = evaluate(ba_kn, X_test, y_test, \"KNN\")\n",
    "\n",
    "# Measure the time taken\n",
    "model4.timetaken[0] = time.time() - time1\n",
    "\n",
    "# Print the evaluation results\n",
    "print(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrj3uNwEvlE-",
    "outputId": "a5f7ba99-3318-4937-ebfa-74829db94c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': 'warn', 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC()\n",
    "print(lsvc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RMmKjyQvlHv",
    "outputId": "60709963-ef8c-4736-eecf-88da71c34e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': [1e-05, 0.001, 0.0001, 0.01, 0.1, 1], 'intercept_scaling': [1, 6, 11, 17, 22, 28, 33, 39, 44, 50], 'dual': [True, False], 'max_iter': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}\n"
     ]
    }
   ],
   "source": [
    "class_weight = [int(x) for x in np.linspace(start=10, stop=110, num=11)]\n",
    "class_weight.append(None)\n",
    "intercept_scaling = [int(x) for x in np.linspace(1, 50, num=10)]\n",
    "# Minimum number of samples required to split a node\n",
    "tol = [0.00001, 0.001, 0.0001, 0.01, 0.1, 1]\n",
    "dual = [True, False]\n",
    "itr = [int(x) for x in np.linspace(100, 2000, num=20)]\n",
    "# Create the random grid\n",
    "param_grid_lsvc = {  #'class_weight':class_weight,\n",
    "    \"tol\": tol,\n",
    "    \"intercept_scaling\": intercept_scaling,\n",
    "    \"dual\": dual,\n",
    "    \"max_iter\": itr,\n",
    "}\n",
    "print(param_grid_lsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3NCOZr5vlKl",
    "outputId": "9e4f73cb-9fad-4c07-d37b-d0e7ceae102a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 2400 candidates, which might total in 7200 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 35 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 46 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 58 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 64 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 70 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 81 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 91 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 98 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 104 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 110 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 122 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 124 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 130 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 138 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 148 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 155 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 166 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 171 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 174 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 183 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 192 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 217 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 222 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 227 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 231 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 235 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 239 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 240 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 241 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 244 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 248 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 254 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 255 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 258 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 261 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 264 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 266 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 272 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 276 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 279 candidates trained until now\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 279 candidates trained until now\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 279 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 311 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 317 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 321 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 325 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 330 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 335 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 342 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 346 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 350 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 355 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 366 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 376 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 388 candidates trained until now\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 388 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 389 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 390 candidates trained until now\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 390 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 393 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 396 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 412 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 422 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 422 candidates were fitted (totalling 1266 fits)\n",
      "Bat model\n",
      "LinearSVC\n",
      "       model  accuracy  precision  recall   f1score  rocauc    logloss  \\\n",
      "0  LinearSVC  0.707792        0.6     0.5  0.545455    0.66  10.532236   \n",
      "\n",
      "   timetaken  \n",
      "0  15.233393  \n",
      "CPU times: total: 6.14 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "time1 = time.time()\n",
    "clf_5 = LinearSVC()\n",
    "\n",
    "nia_search5 = NatureInspiredSearchCV(\n",
    "    clf_5,\n",
    "    param_grid_lsvc,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba', #  bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    \n",
    "    # or any number if you want same results on each run\n",
    ")\n",
    "\n",
    "\n",
    "nia_search5.fit(X_train, y_train)\n",
    "print(\"Bat model\")\n",
    "\n",
    "print(\"LinearSVC\")\n",
    "\n",
    "ba_lsvc= nia_search5.best_estimator_\n",
    "model5=evaluate(ba_lsvc , X_test,  y_test, 'LinearSVC')\n",
    "model5.timetaken[0] = time.time() - time1\n",
    "print(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGnKuZCIwU4O",
    "outputId": "36d9d2b4-31cf-4c3d-d70c-c916ab015cb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 1e-05, 'intercept_scaling': 50, 'dual': False, 'max_iter': 1600}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nia_search5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSKqvdW5w_YS",
    "outputId": "d8966e6d-cbfe-41c9-95fb-47e900cd5fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priors': None, 'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "print(gnb.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxCfVONkw_g-",
    "outputId": "305ccdac-8681-406a-a082-3f5d7ebbd7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': [1e-10, 1e-06, 0.01, 0.001, 1e-14, 1, 1e-15, 1e-20]}\n"
     ]
    }
   ],
   "source": [
    "priors = [X_train, y_train]\n",
    "priors.append(None)\n",
    "var_smoothing = [\n",
    "    0.0000000001,\n",
    "    0.000001,\n",
    "    0.01,\n",
    "    0.001,\n",
    "    0.00000000000001,\n",
    "    1,\n",
    "    1e-15,\n",
    "    1e-20,\n",
    "]\n",
    "param_grid_gnb = {\"var_smoothing\": var_smoothing}  #'priors':priors,\n",
    "print(param_grid_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7bhXWMEw_kX",
    "outputId": "aab3041a-4e8f-4cd2-9c82-c2a250f2ba9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 8 candidates, which might total in 24 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 8 candidates trained until now\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 8 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 8 candidates trained until now\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 8 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 8 candidates trained until now\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 8 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 8 candidates were fitted (totalling 24 fits)\n",
      "Bat model\n",
      "GaussianNB\n",
      "        model  accuracy  precision   recall   f1score    rocauc    logloss  \\\n",
      "0  GaussianNB  0.701299   0.566667  0.62963  0.596491  0.684815  10.766286   \n",
      "\n",
      "   timetaken  \n",
      "0   0.286966  \n",
      "CPU times: total: 109 ms\n",
      "Wall time: 291 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "time1 = time.time()\n",
    "clf_6 = GaussianNB()\n",
    "\n",
    "nia_search6 = NatureInspiredSearchCV(\n",
    "    clf_6,\n",
    "    param_grid_gnb,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba', #  bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    \n",
    "    # or any number if you want same results on each run\n",
    ")\n",
    "\n",
    "\n",
    "nia_search6.fit(X_train, y_train)\n",
    "print(\"Bat model\")\n",
    "\n",
    "print(\"GaussianNB\")\n",
    "\n",
    "ba_gnb= nia_search6.best_estimator_\n",
    "model6=evaluate(ba_gnb , X_test,  y_test, 'GaussianNB')\n",
    "model6.timetaken[0] = time.time() - time1\n",
    "print(model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmgUiNSbyEL_",
    "outputId": "c1228168-fdce-4782-8baa-e2350ae14af9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=1e-15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB(var_smoothing=1e-15)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB(var_smoothing=1e-15)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nia_search6.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcmSGoOQycGt",
    "outputId": "bbaedd2e-18fd-4a3a-acd4-04a24b1acffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "print(svc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_46vJaaycI4",
    "outputId": "1d2a3a81-3061-4ab5-e755-f91a090804f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'tol': [1e-05, 0.001, 0.0001, 0.01, 0.1, 1], 'cache_size': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'break_ties': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "degree = [int(x) for x in np.linspace(start=1, stop=20, num=20)]\n",
    "# class_weight.append(None)\n",
    "cache_size = [int(x) for x in np.linspace(200, 2000, num=10)]\n",
    "# Minimum number of samples required to split a node\n",
    "tol = [0.00001, 0.001, 0.0001, 0.01, 0.1, 1]\n",
    "break_ties = [True, False]\n",
    "# Create the random grid\n",
    "param_grid_svc = {\n",
    "    \"degree\": degree,\n",
    "    \"tol\": tol,\n",
    "    \"cache_size\": cache_size,\n",
    "    \"break_ties\": break_ties,\n",
    "}\n",
    "print(param_grid_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kew0_5oZycMQ",
    "outputId": "4e888700-d976-43c6-e3a7-03d085671f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for some of the 2400 candidates, which might total in 7200 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 1/100 | Stagnation 0/20 | There were 39 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 2/100 | Stagnation 1/20 | There were 50 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 3/100 | Stagnation 2/20 | There were 62 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 4/100 | Stagnation 3/20 | There were 73 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 5/100 | Stagnation 4/20 | There were 83 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 6/100 | Stagnation 5/20 | There were 91 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 7/100 | Stagnation 6/20 | There were 100 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 8/100 | Stagnation 7/20 | There were 113 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 9/100 | Stagnation 8/20 | There were 124 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 10/100 | Stagnation 9/20 | There were 131 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 11/100 | Stagnation 10/20 | There were 138 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 12/100 | Stagnation 11/20 | There were 150 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 13/100 | Stagnation 12/20 | There were 159 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 14/100 | Stagnation 13/20 | There were 167 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 15/100 | Stagnation 14/20 | There were 175 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 16/100 | Stagnation 15/20 | There were 179 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 17/100 | Stagnation 16/20 | There were 181 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 18/100 | Stagnation 17/20 | There were 192 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 19/100 | Stagnation 18/20 | There were 203 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 20/100 | Stagnation 19/20 | There were 213 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 1/3, Iteration 21/100 | Stagnation 20/20 | There were 216 candidates trained until now\n",
      "Run 1/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 1/100 | Stagnation 0/20 | There were 244 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 2/100 | Stagnation 1/20 | There were 254 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 3/100 | Stagnation 2/20 | There were 263 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 4/100 | Stagnation 3/20 | There were 269 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 5/100 | Stagnation 4/20 | There were 276 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 6/100 | Stagnation 5/20 | There were 282 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 7/100 | Stagnation 6/20 | There were 288 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 8/100 | Stagnation 7/20 | There were 297 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 9/100 | Stagnation 8/20 | There were 300 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 10/100 | Stagnation 9/20 | There were 307 candidates trained until now\n",
      "Run 2/3, Iteration 11/100 | Stagnation 10/20 | There were 307 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 12/100 | Stagnation 11/20 | There were 312 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 13/100 | Stagnation 12/20 | There were 315 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 14/100 | Stagnation 13/20 | There were 317 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 15/100 | Stagnation 14/20 | There were 321 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 16/100 | Stagnation 15/20 | There were 328 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 17/100 | Stagnation 16/20 | There were 336 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 18/100 | Stagnation 17/20 | There were 343 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 19/100 | Stagnation 18/20 | There were 349 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 20/100 | Stagnation 19/20 | There were 357 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 2/3, Iteration 21/100 | Stagnation 20/20 | There were 362 candidates trained until now\n",
      "Run 2/3 finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 1/100 | Stagnation 0/20 | There were 385 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 2/100 | Stagnation 1/20 | There were 392 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 3/100 | Stagnation 2/20 | There were 399 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 4/100 | Stagnation 3/20 | There were 402 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 5/100 | Stagnation 4/20 | There were 406 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 6/100 | Stagnation 5/20 | There were 412 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 7/100 | Stagnation 6/20 | There were 414 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 8/100 | Stagnation 7/20 | There were 416 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 9/100 | Stagnation 8/20 | There were 419 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 10/100 | Stagnation 9/20 | There were 420 candidates trained until now\n",
      "Run 3/3, Iteration 11/100 | Stagnation 10/20 | There were 420 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 12/100 | Stagnation 11/20 | There were 422 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 13/100 | Stagnation 12/20 | There were 424 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 14/100 | Stagnation 13/20 | There were 427 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 15/100 | Stagnation 14/20 | There were 431 candidates trained until now\n",
      "Run 3/3, Iteration 16/100 | Stagnation 15/20 | There were 431 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 17/100 | Stagnation 16/20 | There were 435 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 18/100 | Stagnation 17/20 | There were 437 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 19/100 | Stagnation 18/20 | There were 439 candidates trained until now\n",
      "Run 3/3, Iteration 20/100 | Stagnation 19/20 | There were 439 candidates trained until now\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Run 3/3, Iteration 21/100 | Stagnation 20/20 | There were 443 candidates trained until now\n",
      "Run 3/3 finished\n",
      "Optimization finished, 443 candidates were fitted (totalling 1329 fits)\n",
      "Bat model\n",
      "SVC\n",
      "  model  accuracy  precision    recall   f1score    rocauc    logloss  \\\n",
      "0   SVC  0.720779   0.648649  0.444444  0.527473  0.657222  10.064137   \n",
      "\n",
      "   timetaken  \n",
      "0  30.452994  \n",
      "CPU times: total: 6.33 s\n",
      "Wall time: 30.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "time1 = time.time()\n",
    "clf_8 = SVC()\n",
    "\n",
    "nia_search8 = NatureInspiredSearchCV(\n",
    "    clf_8,\n",
    "    param_grid_svc,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    algorithm='ba', #  bat algorithm\n",
    "    population_size=50,\n",
    "    max_n_gen=100,\n",
    "    max_stagnating_gen=20,\n",
    "    runs=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    \n",
    "    # or any number if you want same results on each run\n",
    ")\n",
    "\n",
    "\n",
    "nia_search8.fit(X_train, y_train)\n",
    "print(\"Bat model\")\n",
    "\n",
    "print(\"SVC\")\n",
    "\n",
    "ba_svc= nia_search8.best_estimator_\n",
    "model8=evaluate(ba_svc , X_test,  y_test, 'SVC')\n",
    "model8.timetaken[0] = time.time() - time1\n",
    "print(model8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzbnwmHHzA1V",
    "outputId": "21ea37db-d4d5-4a24-891e-d7992b392589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degree': 16, 'tol': 0.0001, 'cache_size': 1800, 'break_ties': False}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nia_search8.best_params_"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BatAlgorithm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
